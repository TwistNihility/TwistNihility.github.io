<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sisyphus&#39;s Utopia</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-04-29T00:24:09.789Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Twist Nihility</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>TFMLC学习笔记（3） 基于TensorFlow的线性回归</title>
    <link href="http://yoursite.com/2018/04/27/TFMLC-3/"/>
    <id>http://yoursite.com/2018/04/27/TFMLC-3/</id>
    <published>2018-04-26T23:44:39.000Z</published>
    <updated>2018-04-29T00:24:09.789Z</updated>
    
    <content type="html"><![CDATA[<p>线性回归算法是统计分析、机器学习和科学计算中最重要的算法之一，也是最常使用的算法之一，所以需要理解其是如何实现的，以及线性回归算法的各种优点。相对于许多其他算法来说，线性回归算法是最易解释的。以每个特征的数值直接代表该特征对目标值或者因变量的影响。</p><ul><li>用TensorFlow求逆矩阵<br>线性回归算法能表示为矩阵计算，Ax=b。这里要解决的是用矩阵x来求解系数。如果观测矩阵不是方阵，那求解出的矩阵x为x=</li></ul><ol><li><p>导入必要的编程库，初始化计算图，并生成数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create graph</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the data</span></span><br><span class="line">x_vals = np.linspace(<span class="number">0</span>, <span class="number">10</span>, <span class="number">100</span>)</span><br><span class="line">y_vals = x_vals + np.random.normal(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br></pre></td></tr></table></figure></li><li><p>创建后续求逆方法所需的矩阵<br>创建A矩阵，其为矩阵x_vals_column和ones_column的合并。然后用矩阵y_vals创建b矩阵：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create design matrix</span></span><br><span class="line">x_vals_column = np.transpose(np.matrix(x_vals))</span><br><span class="line">ones_column = np.transpose(np.matrix(np.repeat(<span class="number">1</span>, <span class="number">100</span>)))</span><br><span class="line">A = np.column_stack((x_vals_column, ones_column))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create b matrix</span></span><br><span class="line">b = np.transpose(np.matrix(y_vals))</span><br></pre></td></tr></table></figure></li><li><p>将A和矩阵转换成张量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create tensors</span></span><br><span class="line">A_tensor = tf.constant(A)</span><br><span class="line">b_tensor = tf.constant(b)</span><br></pre></td></tr></table></figure></li><li><p>使用TensorFlow的tf.matrix_inverse()方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Matrix inverse solution</span></span><br><span class="line">tA_A = tf.matmul(tf.transpose(A_tensor), A_tensor)</span><br><span class="line">tA_A_inv = tf.matrix_inverse(tA_A)</span><br><span class="line">product = tf.matmul(tA_A_inv, tf.transpose(A_tensor))</span><br><span class="line">solution = tf.matmul(product, b_tensor)</span><br><span class="line"></span><br><span class="line">solution_eval = sess.run(solution)</span><br></pre></td></tr></table></figure></li><li><p>从解中抽取系数、斜率和y截距y-intercept：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Extract coefficients</span></span><br><span class="line">slope = solution_eval[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">y_intercept = solution_eval[<span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">print(<span class="string">'slope: '</span> + str(slope))</span><br><span class="line">print(<span class="string">'y_intercept: '</span> + str(y_intercept))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get best fit line</span></span><br><span class="line">best_fit = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> x_vals:</span><br><span class="line">  best_fit.append(slope*i+y_intercept)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the results</span></span><br><span class="line">plt.plot(x_vals, y_vals, <span class="string">'o'</span>, label=<span class="string">'Data'</span>)</span><br><span class="line">plt.plot(x_vals, best_fit, <span class="string">'r-'</span>, label=<span class="string">'Best fit line'</span>, linewidth=<span class="number">3</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'upper left'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></li></ol><p>输出：<br>slope: 0.955707151739<br>y_intercept: 0.174366829314</p><ul><li>用TensorFlow实现矩阵分解<br>本节将用TensorFlow为线性回归算法实现矩阵分解。特别地，我们会使用Cholesky矩阵分解法，相关的函数已在TensorFlow中实现。<br>在上一小节实现的求逆矩阵的方法在大部分情况下是低效率的，尤其是当矩阵非常大时。另一种实现方法是矩阵分解，此方法使用TensorFlow内建的Cholesky矩阵分解法。用户对分解一个矩阵为多个矩阵感兴趣的原因是，结果矩阵的特性使得其在应用中更高效。Cholesky矩阵分解法把一个矩阵分解为上三角矩阵和下三角矩阵，L和L’（L和L’互为转置矩阵）。求解Ax=b，改写为LL’x=b。首先求解Ly=b，然后求解L’x=y得到系数矩阵x。</li></ul><ol><li><p>导入编程库，初始化计算图，生成数据集，获取矩阵A和b：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> ops</span><br><span class="line">ops.reset_default_graph()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create graph</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the data</span></span><br><span class="line">x_vals = np.linspace(<span class="number">0</span>, <span class="number">10</span>, <span class="number">100</span>)</span><br><span class="line">y_vals = x_vals + np.random.normal(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create design matrix</span></span><br><span class="line">x_vals_column = np.transpose(np.matrix(x_vals))</span><br><span class="line">ones_column = np.transpose(np.matrix(np.repeat(<span class="number">1</span>, <span class="number">100</span>)))</span><br><span class="line">A = np.column_stack((x_vals_column, ones_column))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create b matrix</span></span><br><span class="line">b = np.transpose(np.matrix(y_vals))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create tensors</span></span><br><span class="line">A_tensor = tf.constant(A)</span><br><span class="line">b_tensor = tf.constant(b)</span><br></pre></td></tr></table></figure></li><li><p>找到方阵的Cholesky矩阵分解，</p></li></ol><ul><li>用TensorFlow实现线性回归算法</li></ul><ul><li>理解线性回归中的损失函数</li></ul><ul><li>用TensorFlow实现戴明回归算法</li></ul><ul><li>用TensorFlow实现lasso回归和岭回归算法</li></ul><ul><li>用TensorFlow实现弹性网络回归算法</li></ul><ul><li>用TensorFlow实现逻辑回归算法</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;线性回归算法是统计分析、机器学习和科学计算中最重要的算法之一，也是最常使用的算法之一，所以需要理解其是如何实现的，以及线性回归算法的各种优点。相对于许多其他算法来说，线性回归算法是最易解释的。以每个特征的数值直接代表该特征对目标值或者因变量的影响。&lt;/p&gt;
&lt;ul&gt;
&lt;li
      
    
    </summary>
    
      <category term="学习笔记" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>JavaScript： 先天不足的畸形儿</title>
    <link href="http://yoursite.com/2018/04/25/the-history-of-javascript/"/>
    <id>http://yoursite.com/2018/04/25/the-history-of-javascript/</id>
    <published>2018-04-24T17:38:13.000Z</published>
    <updated>2018-04-29T03:24:18.907Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;前端是痛苦的。先来看这几个名词：ECMAScript、JavaScript、Java、JScript。<br>&emsp;曾经，有同学问我：“JavaScript和Java是什么关系？”我说，就是社会主义和中国特色社会主义之间的关系。<br>&emsp;先来解释上面的这几个名词吧。当年网景公司开发出了一门浏览器语言，为了蹭Java的热度，和Sun公司一起搞了个大新闻，把这门浏览器脚本语言命名为JavaScript——人家就是故意让大家误会的。JavaScript后来上交给了国际标准化组织ECMA。ECMA在第一版的JavaScript的基础上制定了一个标准，这就是ECMAScript。总的来说，ECMAScript是实现标准，JavaScript和JScript以及后来诞生的许多XXScript脚本语言都是ECMAScript的实现。ECMAScript是普通话/汉语/中文，JavaScript是北京话，JScript是粤语。<br>&emsp;除了名称上的混乱，前端开发的一大困境就是要面对数不清的框架。Angular.js，jQuery，Node.js，element.js，vue.js等等等等，一年出一个新框架，一辈子都学不完。。每一个从其他语言迁移来的都很疑惑，到底是为什么？为什么JavaScript会诞生这么多的变体？<br>&emsp;我想，最好的办法就是回溯JavaScript出生的那一天，回到它的产房，看看那一天究竟发生了什么。<br>&emsp;JavaScript诞生于浏览器的鼻祖网景公司（Netscape）。大约是1994年左右，网景公司（Netscape）发布了Navigator浏览器0.9版，这是一款很经典的浏览器，网景公司（Netscape）的用户数因此而出现了井喷的态势，但是Navigator0.9不具备和访问者互动的能力，在那个上网速度比蜗牛还慢的时代，网景公司（Netscape）急需一种脚本语言，使得浏览器和网页进行交互，从而提升用户的体验。<br>&emsp;针对这个问题，网景公司（Netscape）有两种选择，一是采用现有的脚本语言，二是自己发明一个新的脚本语言。当时网景公司（Netscape）的高层对这个问题争论不休。在这些喋喋不休的争论里，时间走到了1995年。这一年发生了一件创造历史的大事件：编程语言Java横空出世，Java凭借“一次编写，到处运行的”强大宣传，大有未来主宰的霸气，这些让网景公司（Netscape）高层们一下子被Java所俘获，如是网景公司（Netscape）和Sun公司结盟，网景公司（Netscape）不仅允许Java程序以applet的形式嵌入到浏览器，直接在浏览器里面运行，甚至还打算把Java作为脚本嵌入到网页，只是最后发现网页会变的过于复杂而放弃，但是JavaScript的Java印记永远都挥之不去。<br>&emsp;事情的转折发生在1995年4月，网景公司（Netscape）录用了Bremdan Eich(布兰登·艾奇)（虽然Bremdan Eich(布兰登·艾奇)是JavaScript的祖师爷，但是他的介入或许也是JavaScript悲剧的开始）。我们还是接着说网景公司（Netscape）吧。1995年5月，网景公司（Netscape）做出了决策，未来的网页脚本语言必须看上去和Java足够相似，但是比Java简单，使得非专业的网页作者能很快的上手。<br>&emsp;Bremdan Eich(布兰登·艾奇)被任命为这个简化版的Java的设计师。但是Bremdan Eich(布兰登·艾奇)对Java一点兴趣都没有，为了应付公司的安排的任务，他只用10天时间就设计出了JavaScript。悲剧就这么诞生了。<br>&emsp;Brendan Eich的主要方向和兴趣是函数式编程，网景公司招聘他的目的，是研究将Scheme语言作为网页脚本语言的可能性。Brendan Eich本人也是这样想的，以为进入新公司后，会主要与Scheme语言打交道。<br>&emsp;10天诞生一种语言，不管怎么说还是要把Brendan Eich当神看。但是这位神创造世界的时间实在太短了，导致很多细节考虑不周，因此JavaScript写出的程序混乱不堪，成了许多程序员的梦魇，差点被人抛弃，直到ajax的出世，才让人们终于找到理由忍受它的畸形。<br>&emsp;总的来说啊，Brendan Eich设计思路是这样的：</p><ol><li>借鉴C语言的基本语法；</li><li>借鉴Java语言的数据类型和内存管理；</li><li>借鉴Scheme语言，将函数提升到”第一等公民”（first class）的地位；</li><li>借鉴Self语言，使用基于原型（prototype）的继承机制。 </li></ol><p>&emsp;所以，JavaScript语言实际上是两种语言风格的混合产物（简化的）函数式编程+（简化的）面向对象编程。这是由Brendan Eich（函数式编程）与网景公司（面向对象编程）共同决定的。<br>&emsp;不管怎么说，JavaScript和Java是有关系的，JavaScript里面有Java的思想。所以说JavaScript和Java无关是不正确的。<br>&emsp;其实一直到现在Brendan Eich还是看不起讨厌Java。假如不是公司决策Brendan Eich绝对不会把Java作为JavaScript的设计原型，即使是现在，Brendan Eich还是讨厌自己的作品。他曾经说过：“与其说我爱JavaScript，不如说我恨它。它是C语言和Self语言的产物。十八世纪英国文学家约翰逊博士说得好：’它的优秀之处并非原创，它的原创之处并不优秀。”是不是很像不受父母欢迎的私生子？<br>&emsp;所有人第一次接触JavaScript面向对象编程时候，大概都是忍着刺痛和模糊看完的。猎奇也好，误解也罢，很多人觉得JavaScript面向对象编程是代码爱好者的游戏，使用价值不大，但其实，JavaScript面向对象编程用途是如此之多令我叹为观止。我们可以说：最好的JavaScript代码都应该是面向对象的。<br>&emsp;那么JavaScript里是如何实现继承的？JavaScript的继承机制如何？<br>&emsp;首先JavaScript里面没有”子类”和”父类”的概念，也没有”类”（class）和”实例”（instance）的区分，全靠一种很奇特的”原型链”（prototype chain）模式，来实现继承。<br>&emsp;网景公司在发明与设计JavaScript的目标，其中很重要的两点：</p><ol><li>简易版的Java；</li><li>简易，简易还是简易。 </li></ol><p>&emsp;Brendan Eich设计JavaScript的时候引入了Java一个非常重要的概念：一切皆对象。既然JavaScript里面有了对象，那么设不设计继承就是困扰Brendan Eich的一个问题，如果真是要设计一个简易的语言其实可以不要继承机制，继承属于专业的程序员，但是JavaScript里那么多的对象，如果没有一种机制，他们之间将如何联系了，这必然会对编写程序的可靠性带来很大的问题，但是引入了继承又会使用JavaScript变成了完整的面向对象的语言，从而提高了它的门槛，让很多初学者望而却步，折中之下，Brendan Eich还是选择设计继承，但绝不是标准的继承（说道这里不禁让人想起同样使用EMCAScript标准设计的语言ActionScript，它里面就有很完整的继承，做起来很惬意，不知道这是不是JavaScript以后的趋势，说不定哪天JavaScript会变的更完美了？）。折中是指Brendan Eich不打算引入类（class），这样JavaScript至少看起来不像面向对象的语言了，那么初学者就不会望而却步了（这是赤裸裸的欺骗，进来后倒腾死你，关门打狗，莫过如此）。<br>&emsp;Brendan Eich思考之后，决定借鉴C++和java的new命令，将new命令引入了JavaScript，在传统的面向对象的语言里，new 用来构造实例对象，new 会调用构造函数，但是传统面向对象的语言new后面的是类，内部机制是调用构造函数（constructor），而Brendan Eich简化了这个操作，在JavaScript里面，new 后面直接是构造函数，如是我们可以这么写一个Person类：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Person</span>(<span class="params">name</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="keyword">this</span>.name = name;</span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line"><span class="keyword">var</span> per = <span class="keyword">new</span> Person(<span class="string">'Brendan Eich'</span>);</span><br><span class="line"><span class="built_in">console</span>.log(per.name);<span class="comment">//Brendan Eich</span></span><br></pre></td></tr></table></figure></p><p>&emsp;这样就创建了一个新的实例了。但是new有缺陷。用构造函数生成实例对象是无法共享属性和方法，例如下面代码：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Person</span>(<span class="params">name</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">     <span class="keyword">this</span>.name = name;</span><br><span class="line">     <span class="keyword">this</span>.nation = <span class="string">'USA'</span>;</span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line"><span class="keyword">var</span> per1 = <span class="keyword">new</span> Person(<span class="string">'Brendan Eich'</span>);</span><br><span class="line"><span class="keyword">var</span> per2 = <span class="keyword">new</span> Person(<span class="string">'蒟蒻'</span>);</span><br><span class="line">per2.nation = <span class="string">'China'</span>;</span><br><span class="line"><span class="built_in">console</span>.log(per1.nation);<span class="comment">//USA</span></span><br><span class="line"><span class="built_in">console</span>.log(per2.nation);<span class="comment">//China</span></span><br></pre></td></tr></table></figure></p><p>&emsp;每一个实例对象，都有自己的属性和方法的副本。这不仅无法做到数据共享，也是极大的资源浪费。和JavaScript工厂模式的缺点一样，过多重复的对象会使得浏览器速度缓慢，造成资源的极大的浪费。<br>&emsp;考虑到这一点，Brendan Eich决定为构造函数设置一个prototype属性，这个属性都是指向一个prototype对象。下面一句话很重要：所有实例对象需要共享的属性和方法，都放在这个对象里面；那些不需要共享的属性和方法，就放在构造函数里面。<br>实例对象一旦创建，将自动引用prototype对象的属性和方法。也就是说，实例对象的属性和方法，分成两种，一种是本地的，另一种是引用的。如是我们可以改写下上面的程序：<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Person</span>(<span class="params">name</span>)</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="keyword">this</span>.name = name;</span><br><span class="line">&#125; </span><br><span class="line">Person.prototype = &#123;<span class="attr">nation</span>:<span class="string">'USA'</span>&#125;;</span><br><span class="line"><span class="keyword">var</span> per1 = <span class="keyword">new</span> Person(<span class="string">'Brendan Eich'</span>);</span><br><span class="line"><span class="keyword">var</span> per2 = <span class="keyword">new</span> Person(<span class="string">'IT民工'</span>); </span><br><span class="line"><span class="built_in">console</span>.log(per1.nation);<span class="comment">//USA</span></span><br><span class="line"><span class="built_in">console</span>.log(per2.nation);<span class="comment">//USA</span></span><br></pre></td></tr></table></figure></p><p>&emsp;当我们这样写程序时候Person.prototype.nation = ‘China’; 所有实例化的类的nation都会变成China。<br>&emsp;由于所有的实例对象共享同一个prototype对象，那么从外界看起来，prototype对象就好像是实例对象的原型，而实例对象则好像”继承”了prototype对象一样。prototype只是提供了实现JavaScript继承的一个很方便的途径和手段。<br>&emsp;原型链是学习JavaScript最大的难点之一。JavaScript足够独特，一路走来足够坎坷。我觉得，当疑惑于JavaScript的某个特性时，不妨回溯历史，仔细体会一下人类智慧的光辉痕迹，也许会有豁然开朗之感。<br>&emsp;JavaScript，网景，以及之后著名的“浏览器大战”，是我本人很喜欢的一段科技史。这段历史，带有一种天生的厚重感。那个时候，波澜壮阔的互联网时代即将拉开帷幕，一片崭新的天地之下，所有事物尚需指指点点。<br>&emsp;作为一门先天不足的语言，JavaScript一路走来经历了太多。有人爱它也好，有人恨它也罢，它兀自默默发着自己的光。我偏爱这样的故事。带着罪恶，残缺和不足诞生，甚至亲生的父母都嫌弃，迎接漫天的谩骂和否定，却仍然带着希望迎来广阔的未来。<br>&emsp;很燃很热血。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&amp;emsp;前端是痛苦的。先来看这几个名词：ECMAScript、JavaScript、Java、JScript。&lt;br&gt;&amp;emsp;曾经，有同学问我：“JavaScript和Java是什么关系？”我说，就是社会主义和中国特色社会主义之间的关系。&lt;br&gt;&amp;emsp;先来解释
      
    
    </summary>
    
      <category term="科普趣谈" scheme="http://yoursite.com/categories/%E7%A7%91%E6%99%AE%E8%B6%A3%E8%B0%88/"/>
    
    
      <category term="JavaScript" scheme="http://yoursite.com/tags/JavaScript/"/>
    
  </entry>
  
  <entry>
    <title>TFMLC学习笔记（2） TensorFlow进阶</title>
    <link href="http://yoursite.com/2018/04/22/TFMLC-2/"/>
    <id>http://yoursite.com/2018/04/22/TFMLC-2/</id>
    <published>2018-04-22T10:50:03.000Z</published>
    <updated>2018-04-29T03:24:13.052Z</updated>
    
    <content type="html"><![CDATA[<h1 id="计算图中的操作"><a href="#计算图中的操作" class="headerlink" title="计算图中的操作"></a>计算图中的操作</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入TensorFlow，创建一个会话，开始一个计算图</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">sess=tf.Session()</span><br><span class="line"></span><br><span class="line"><span class="comment">#传入一个列表到计算图中的操作，并打印返回值</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x_vals=np.array([<span class="number">1.</span>, <span class="number">3.</span>, <span class="number">5.</span>, <span class="number">7.</span>, <span class="number">9.</span>])                            <span class="comment">#创建一个numpy数组</span></span><br><span class="line">x_data=tf.palceholder(tf.float32)                                <span class="comment">#声明占位符</span></span><br><span class="line">m_const=tf.constant(<span class="number">3.</span>)                                          <span class="comment">#声明张量</span></span><br><span class="line">my_product=tf.mul(x_data,m_const)</span><br><span class="line"><span class="keyword">for</span> x_val <span class="keyword">in</span> x_vals:</span><br><span class="line">    print(sess.run(my_product,feed_dict=&#123;x_data:x_val&#125;))</span><br><span class="line"><span class="number">3.0</span></span><br><span class="line"><span class="number">9.0</span></span><br><span class="line"><span class="number">15.0</span></span><br><span class="line"><span class="number">21.0</span></span><br><span class="line"><span class="number">27.0</span></span><br></pre></td></tr></table></figure><h1 id="TensorFlow的嵌入Layer"><a href="#TensorFlow的嵌入Layer" class="headerlink" title="TensorFlow的嵌入Layer"></a>TensorFlow的嵌入Layer</h1><p>本节学习如何在同一个计算图中进行多个乘法操作。下面将用两个矩阵乘以占位符，然后做加法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入TensorFlow，创建一个会话，开始一个计算图</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">sess=tf.Session()</span><br></pre></td></tr></table></figure></p><p>我们将传入两个形状为3x5的numpy数组，然后每个矩阵乘以常量矩阵（形状：5x1），将返回一个形状为3x1的矩阵。然后再乘以1x1的矩阵，返回的结果矩阵仍然为3x1。最后，加上一个3x1的矩阵。</p><ol><li><p>首先，创建数据和占位符</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">my_array=np.array([[ <span class="number">1.</span>, <span class="number">3.</span>,<span class="number">5.</span>,<span class="number">7.</span>,<span class="number">9.</span>],</span><br><span class="line">                   [<span class="number">-2.</span>, <span class="number">0.</span>,<span class="number">2.</span>,<span class="number">4.</span>,<span class="number">6.</span>],</span><br><span class="line">                   [<span class="number">-6.</span>,<span class="number">-3.</span>,<span class="number">0.</span>,<span class="number">3.</span>,<span class="number">6.</span>]])</span><br><span class="line">x_vals=np.array([my_array,my_array+<span class="number">1</span>])</span><br><span class="line">x_data=tf.placeholder(tf.float32,shape=(<span class="number">3</span>,<span class="number">5</span>))</span><br></pre></td></tr></table></figure></li><li><p>接着，创建矩阵乘法和加法中要用到的常量矩阵</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">m1=tf.constant([[<span class="number">1.</span>],[<span class="number">0.</span>],[<span class="number">-1.</span>],[<span class="number">2.</span>],[<span class="number">4.</span>]])</span><br><span class="line">m2=tf.constant([[<span class="number">2.</span>]])</span><br><span class="line">a1=tf.constant([[<span class="number">10.</span>]])</span><br></pre></td></tr></table></figure></li><li><p>声明操作，表示成计算图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">prod1=tf.matmul(x_data,m1)</span><br><span class="line">prod2=tf.matmul(prod1,m2)</span><br><span class="line">add1=tf.add(prod2,a1)</span><br></pre></td></tr></table></figure></li><li><p>最后，通过计算图赋值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> x_val <span class="keyword">in</span> x_vals:</span><br><span class="line">    print(sess.run(add1,feed_dict=&#123;x_data:x_val&#125;))</span><br><span class="line">[[<span class="number">102.</span>]</span><br><span class="line"> [ <span class="number">66.</span>]</span><br><span class="line"> [ <span class="number">58.</span>]]</span><br><span class="line">[[<span class="number">114.</span>]</span><br><span class="line"> [ <span class="number">78.</span>]</span><br><span class="line"> [ <span class="number">70.</span>]]</span><br></pre></td></tr></table></figure></li></ol><h1 id="TensorFlow的多层Layer"><a href="#TensorFlow的多层Layer" class="headerlink" title="TensorFlow的多层Layer"></a>TensorFlow的多层Layer</h1><p>本节中，将介绍如何更好地连接多层Layer，包括自定义Layer。这里给出一个例子（数据是生成随机图片数据），以更好地理解不同类型的操作和如何利用内建层Layer进行计算。我们对2D图像进行滑动窗口平均，然后通过自定义操作层Layer返回结果。<br>在本节，TensorFlow的计算图太大，导致无法完整查看。为了解决此问题，将对各层Layer和操作进行层级命名管理。<br>按照惯例，加载numpy和TensorFlow模块，创建计算图：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">sess=tf.Session()</span><br></pre></td></tr></table></figure></p><ol><li><p>首先通过numpy创建2D图像，4x4像素图片。我们将创建成四维：第一维和最后一维大小为1。注意TensorFlow的图像函数是处理四维图片的，这四维是：图片数量、高度、宽度、颜色通道。这里是一张图片，单颜色通道，所以设两个维度值为1：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_shape=[<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">1</span>]</span><br><span class="line">x_val=np.random.uniform(size=x_shape)</span><br></pre></td></tr></table></figure></li><li><p>下面在计算图中创建占位符。此例中占位符是用来传入图片的，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_data=tf.placeholder(tf.float32,shape=x_shape)</span><br></pre></td></tr></table></figure></li><li><p>为了创建过滤4x4像素图片的滑动窗口，我们将用TensorFlow内建函数conv2d()（常用来做图像处理）卷积2x2形状的常量窗口。con2d()函数传入滑动窗口、过滤器和步长。本例将在滑动窗口四个方向上计算，所以在四个方向上都要指定步长。创建一个2x2的窗口，每个方向长度为2的步长。为了计算平均值，用常量为0.25的向量与2x2的窗口卷积：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">my_filter=tf.constant(<span class="number">0.25</span>,shape=[<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">my_strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>]</span><br><span class="line">mov_avg_layer=tf.nn.conv2d(x_data,my_filter,my_strides,padding=<span class="string">'SAME'</span>,name=<span class="string">'Moving_Avg_Window'</span>)</span><br></pre></td></tr></table></figure></li><li><p>注意，我们通过conv2d()函数的name参数，把这层Layer命名为“Moving_Avg_Window”。</p></li><li><p>现在定义一个自定义Layer，操作滑动窗口平均的2x2的返回值。自定义函数将输入张量乘以一个2x2的矩阵张量，然后每个元素加1.因为矩阵乘法只计算二维矩阵，所以剪裁图像的多余维度（大小为1）。TensorFlow通过内建函数squeeze()剪裁。下面是新定义的Layer：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Define a custom layer which will be sigmoid(Ax+b) where x is a 2x2 matrix and A and b are 2x2 matrices</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">custom_layer</span><span class="params">(input_matrix)</span>:</span></span><br><span class="line">    input_matrix_sqeezed = tf.squeeze(input_matrix)</span><br><span class="line">    A = tf.constant([[<span class="number">1.</span>, <span class="number">2.</span>], [<span class="number">-1.</span>, <span class="number">3.</span>]])</span><br><span class="line">    b = tf.constant(<span class="number">1.</span>, shape=[<span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line">    temp1 = tf.matmul(A, input_matrix_sqeezed)</span><br><span class="line">    temp = tf.add(temp1, b) <span class="comment"># Ax + b</span></span><br><span class="line">    <span class="keyword">return</span>(tf.sigmoid(temp))</span><br></pre></td></tr></table></figure></li><li><p>现在把刚刚新定义的Layer加入到计算图中，并且用tf.name_scope()命名唯一的Layer名字，后续在计算图中可折叠/扩展Custom_Layer层。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add custom layer to graph</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'Custom_Layer'</span>) <span class="keyword">as</span> scope:</span><br><span class="line">    custom_layer1 = custom_layer(mov_avg_layer)</span><br></pre></td></tr></table></figure></li><li><p>为占位符传入4x4像素图片，然后执行计算图，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># After custom operation, size is now 2x2 (squeezed out size 1 dims)</span></span><br><span class="line">print(sess.run(custom_layer1, feed_dict=&#123;x_data: x_val&#125;))</span><br><span class="line">[[<span class="number">0.91914582</span> <span class="number">0.96025133</span>]</span><br><span class="line"> [<span class="number">0.87262219</span> <span class="number">0.9469803</span>]]</span><br></pre></td></tr></table></figure></li></ol><h1 id="TensorFlow实现损失函数"><a href="#TensorFlow实现损失函数" class="headerlink" title="TensorFlow实现损失函数"></a>TensorFlow实现损失函数</h1><p>为了优化机器学习学习算法，我们需要评估机器学习模型训练输出结果。在TensorFlow中评估输出结果依赖损失函数。损失函数告诉TensorFlow，预测结果相比期望的结果是好是坏。在大部分场景下，我们会有算法模型训练的样本数据集和目标值。损失函数比较预测值与目标值，并给出两者之间的数值化的差值。<br>为了比较不同损失函数的区别，需要用图表将它们绘制出来。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt      <span class="comment">#加载matplotlib（Python的绘图库）</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure></p><ol><li>回归算法的损失函数。回归算法是预测连续因变量的。创建预测序列和目标序列作为张量，预测序列是-1到1之间的等差数列。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Numerical Predictions</span></span><br><span class="line">x_vals = tf.linspace(<span class="number">-1.</span>, <span class="number">1.</span>, <span class="number">500</span>)</span><br><span class="line">target = tf.constant(<span class="number">0.</span>)</span><br></pre></td></tr></table></figure></li></ol><ul><li>L2正则损失函数（欧拉损失函数）<br>L2正则损失函数是预测值与目标值差值的平方和。注意：上述例子中目标值为0。L2正则损失函数是非常有用的损失函数，因为它在目标值附近有更好的曲度，机器学习算法利用这点收敛，并且离目标越近收敛越慢。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># L2 loss</span></span><br><span class="line"><span class="comment"># L = (pred - actual)^2</span></span><br><span class="line">l2_y_vals=tf.square(target-x_vals)</span><br><span class="line">l2_y_out=sess.run(l2_y_vals)</span><br></pre></td></tr></table></figure></li></ul><p>TensorFlow有内建的L2正则形式，称为nn.l2_loss()。这个函数是实际L2正则的一半，即，上述l2_y_vals的1/2</p><ul><li>L1正则损失函数（绝对值损失函数）<br>与L2正则损失函数对差值求平方不同的是，L1正则损失函数对差值求绝对值。L1正则在目标值附近不平滑，这会导致算法不能很好的收敛。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># L1 loss</span></span><br><span class="line"><span class="comment"># L = abs(pred - actual)</span></span><br><span class="line">l1_y_vals = tf.abs(target - x_vals)</span><br><span class="line">l1_y_out = sess.run(l1_y_vals)</span><br></pre></td></tr></table></figure></li></ul><ul><li>Pseudo-Huber损失函数<br>Pseudo-Huber损失函数是Huber损失函数的连续、平滑估计，试图利用L1和L2正则削减极值处的陡峭，使得目标值附近连续。它的表达式依赖参数delta。我们将绘图来显示delta1=0.25和delta2=5的区别：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Pseudo-Huber loss</span></span><br><span class="line"><span class="comment"># L = delta^2 * (sqrt(1 + ((pred - actual)/delta)^2) - 1)</span></span><br><span class="line">delta1 = tf.constant(<span class="number">0.25</span>)</span><br><span class="line">phuber1_y_vals = tf.multiply(tf.square(delta1), tf.sqrt(<span class="number">1.</span> + tf.square((target - x_vals)/delta1)) - <span class="number">1.</span>)</span><br><span class="line">phuber1_y_out = sess.run(phuber1_y_vals)</span><br><span class="line"></span><br><span class="line">delta2 = tf.constant(<span class="number">5.</span>)</span><br><span class="line">phuber2_y_vals = tf.multiply(tf.square(delta2), tf.sqrt(<span class="number">1.</span> + tf.square((target - x_vals)/delta2)) - <span class="number">1.</span>)</span><br><span class="line">phuber2_y_out = sess.run(phuber2_y_vals)</span><br></pre></td></tr></table></figure></li></ul><ol start="2"><li>分类损失函数<br>分类损失函数用来评估预测分类结果。<br>重新给x_vals和target赋值，保存返回值并在下节绘制出来。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_vals = tf.linspace(<span class="number">-3.</span>, <span class="number">5.</span>, <span class="number">500</span>)</span><br><span class="line">target = tf.constant(<span class="number">1.</span>)</span><br><span class="line">targets = tf.fill([<span class="number">500</span>,], <span class="number">1.</span>)</span><br></pre></td></tr></table></figure></li></ol><ul><li>Hinge损失函数<br>Hinge损失函数主要用来评估支持向量机算法，但有时也用来评估神经网络算法。在本例中是计算两个目标类（-1,1）之间的损失。下面的代码中，使用目标值1，所以预测值离1越近，损失函数值越小：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Hinge loss</span></span><br><span class="line"><span class="comment"># Use for predicting binary (-1, 1) classes</span></span><br><span class="line"><span class="comment"># L = max(0, 1 - (pred * actual))</span></span><br><span class="line">hinge_y_vals = tf.maximum(<span class="number">0.</span>, <span class="number">1.</span> - tf.multiply(target, x_vals))</span><br><span class="line">hinge_y_out = sess.run(hinge_y_vals)</span><br></pre></td></tr></table></figure></li></ul><ul><li>两类交叉熵损失函数（Cross-entropy loss）<br>两类交叉熵损失函数（Cross-entropy loss）有时也作为逻辑损失函数。比如，当预测两类目标0或者1时，希望度量预测值到真实分类值（0或1）的距离，这个距离经常是0到1之间的实数。为了度量这个距离，使用信息论中的交叉熵。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Cross entropy loss</span></span><br><span class="line"><span class="comment"># L = -actual * (log(pred)) - (1-actual)(log(1-pred))</span></span><br><span class="line">xentropy_y_vals = - tf.multiply(target, tf.log(x_vals)) - tf.multiply((<span class="number">1.</span> - target), tf.log(<span class="number">1.</span> - x_vals))</span><br><span class="line">xentropy_y_out = sess.run(xentropy_y_vals)</span><br></pre></td></tr></table></figure></li></ul><ul><li>Sigmoid交叉熵损失函数（Sigmoid cross entropy loss）<br>Sigmoid交叉熵损失函数与两类交叉熵损失函数非常相似，区别在于：Sigmoid交叉熵损失函数先把x_vals值通过sigmoid函数转换，再计算交叉熵损失。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">xentropy_sigmoid_y_vals=tf.nn.sigmoid_cross_entropy_with_logits(x_vals,targets)</span><br><span class="line">xentropy_sigmoid_y_out=sess.run(xentropy_sigmoid_y_vals)</span><br></pre></td></tr></table></figure></li></ul><ul><li>加权交叉熵损失函数（Weighted cross entropy loss）<br>加权交叉熵损失函数是Sigmoid交叉熵损失函数的加权，对正目标加权。例如，将正目标加权权重0.5<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Weighted (softmax) cross entropy loss</span></span><br><span class="line"><span class="comment"># L = -actual * (log(pred)) * weights - (1-actual)(log(1-pred))</span></span><br><span class="line"><span class="comment"># or</span></span><br><span class="line"><span class="comment"># L = (1 - pred) * actual + (1 + (weights - 1) * pred) * log(1 + exp(-actual))</span></span><br><span class="line">weight = tf.constant(<span class="number">0.5</span>)</span><br><span class="line">xentropy_weighted_y_vals = tf.nn.weighted_cross_entropy_with_logits(x_vals,targets,weight)</span><br><span class="line">xentropy_weighted_y_out = sess.run(xentropy_weighted_y_vals)</span><br></pre></td></tr></table></figure></li></ul><ul><li>Softmax交叉熵损失函数（Softmax cross-entropy loss）<br>Softmax交叉熵损失函数是作用于非归一化的输出结果，只针对单个目标分类的计算损失。通过softmax函数将输出结果转化成概率分布，然后计算真值概率分布的损失<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Softmax entropy loss</span></span><br><span class="line"><span class="comment"># L = -actual * (log(softmax(pred))) - (1-actual)(log(1-softmax(pred)))</span></span><br><span class="line">unscaled_logits = tf.constant([[<span class="number">1.</span>, <span class="number">-3.</span>, <span class="number">10.</span>]])</span><br><span class="line">target_dist = tf.constant([[<span class="number">0.1</span>, <span class="number">0.02</span>, <span class="number">0.88</span>]])</span><br><span class="line">softmax_xentropy = tf.nn.softmax_cross_entropy_with_logits_v2(unscaled_logits,target_dist)</span><br><span class="line">print(sess.run(softmax_xentropy))</span><br><span class="line">[<span class="number">1.16012561</span>]</span><br></pre></td></tr></table></figure></li></ul><ul><li>稀疏Softmax交叉熵损失函数（Sparse softmax cross-entropy loss）<br>稀疏Softmax交叉熵损失函数和Softmax交叉熵损失函数类似，它是把目标分类为true的转化成index，而Softmax交叉熵损失函数将目标转成概率分布。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Sparse entropy loss</span></span><br><span class="line"><span class="comment"># Use when classes and targets have to be mutually exclusive</span></span><br><span class="line"><span class="comment"># L = sum( -actual * log(pred) )</span></span><br><span class="line">unscaled_logits = tf.constant([[<span class="number">1.</span>, <span class="number">-3.</span>, <span class="number">10.</span>]])</span><br><span class="line">sparse_target_dist = tf.constant([<span class="number">2</span>])</span><br><span class="line">sparse_xentropy =  tf.nn.sparse_softmax_cross_entropy_with_logits(unscaled_logits,sparse_target_dist)</span><br><span class="line">print(sess.run(sparse_xentropy))</span><br><span class="line">[<span class="number">0.00012564</span>]</span><br></pre></td></tr></table></figure></li></ul><p>3.绘制各类损失函数</p><ul><li>用matplotlib绘制回归算法的损失函数<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot the output:</span></span><br><span class="line">x_array = sess.run(x_vals)</span><br><span class="line">plt.plot(x_array, l2_y_out, <span class="string">'b-'</span>, label=<span class="string">'L2 Loss'</span>)</span><br><span class="line">plt.plot(x_array, l1_y_out, <span class="string">'r--'</span>, label=<span class="string">'L1 Loss'</span>)</span><br><span class="line">plt.plot(x_array, phuber1_y_out, <span class="string">'k-.'</span>, label=<span class="string">'P-Huber Loss (0.25)'</span>)</span><br><span class="line">plt.plot(x_array, phuber2_y_out, <span class="string">'g:'</span>, label=<span class="string">'P-Huber Loss (5.0)'</span>)</span><br><span class="line">plt.ylim(<span class="number">-0.2</span>, <span class="number">0.4</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'lower right'</span>, prop=&#123;<span class="string">'size'</span>: <span class="number">11</span>&#125;)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></li></ul><p><img src="data:image/png;base64,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" alt="avatar"></p><ul><li>用matplotlib绘制分类算法的损失函数<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot the output</span></span><br><span class="line">x_array = sess.run(x_vals)</span><br><span class="line">plt.plot(x_array, hinge_y_out, <span class="string">'b-'</span>, label=<span class="string">'Hinge Loss'</span>)</span><br><span class="line">plt.plot(x_array, xentropy_y_out, <span class="string">'r--'</span>, label=<span class="string">'Cross Entropy Loss'</span>)</span><br><span class="line">plt.plot(x_array, xentropy_sigmoid_y_out, <span class="string">'k-.'</span>, label=<span class="string">'Cross Entropy Sigmoid Loss'</span>)</span><br><span class="line">plt.plot(x_array, xentropy_weighted_y_out, <span class="string">'g:'</span>, label=<span class="string">'Weighted Cross Entropy Loss (x0.5)'</span>)</span><br><span class="line">plt.ylim(<span class="number">-1.5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment">#plt.xlim(-1, 3)</span></span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend(loc=<span class="string">'lower right'</span>, prop=&#123;<span class="string">'size'</span>: <span class="number">11</span>&#125;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></li></ul><p><img src="data:image/png;base64,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" alt="avatar"></p><ol start="4"><li><p>总结<br>|损失函数|使用类型|优点|缺点|<br>|:-:|:-:|:-:|:-:|<br>|L2|回归算法|更稳定|缺少健壮|<br>|L1|回归算法|更健壮|缺少稳定|<br>|Psuedo-Huber|回归算法|更健壮、稳定参数多|<br>|Hinge|分类算法|常用于SVM的最大距离|异常值导致无边界损失|<br>|Cross-entropy|分类算法|更稳定|缺少健壮，出现无边界损失|</p></li><li><p>评价机器学习模型的其他指标<br>|模型指标|描述|<br>|:-:|:-:|<br>|R平方值（R-squared）|对简单的线性模型来讲，用于度量因变量的变异中可由自变量解释部分所占的比例|<br>|RMSE（平均方差）|对连续模型来讲，平均方差是度量预测的值和观察到的值之差的样本标准差|<br>|混淆矩阵（Confusion matrix）|对分类模型来讲，以矩阵形式将数据集中的记录按照真实的类别与分类模型预测的分类判断两个标准进行分析汇总，其每一列代表预测值，每一行代表的是实际的类别。理想情况下，混淆矩阵是对角矩阵|<br>|召回率（Recall）|对于分类模型来讲，召回率是正类预测为正类数与所有预测正类数的比值|<br>|精准度（Precision）|对于分类模型来讲，精准度是正类预测为正类数与所有实际正类数的比值|<br>|F值（F-score）|对于分类模型来讲，F值是召回率和精准度的调和平均数|</p></li></ol><h1 id="TensorFlow实现反向传播"><a href="#TensorFlow实现反向传播" class="headerlink" title="TensorFlow实现反向传播"></a>TensorFlow实现反向传播</h1><p>TensorFlow可以维护操作状态和基于反向传播自动地更新模型变量。通过计算图来更新变量，通过最小化损失函数来反向传播误差。实现方法是声明优化函数（optimization function）。一旦声明好优化函数，TensorFlow将通过优化函数在所有的计算图中解决反向传播的项。当传入数据和最小化损失函数，TensorFlow会在计算图中根据状态相应调节变量。</p><ol><li>回归算法举例<br>从均值为1，标准差为0.1的正态分布中抽样随机数，然后乘以变量A，损失函数为L2正则损失函数。理论上，A的最优值是10，因为生成的样例数据均值是1。</li></ol><ul><li>导入Python的数值计算模块，numpy和tensorflow：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure></li></ul><ul><li>创建计算图会话:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create graph</span></span><br><span class="line">sess = tf.Session()</span><br></pre></td></tr></table></figure></li></ul><ul><li>生成数据，创建占位符和变量A:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create data</span></span><br><span class="line">x_vals = np.random.normal(<span class="number">1</span>, <span class="number">0.1</span>, <span class="number">100</span>)</span><br><span class="line">y_vals = np.repeat(<span class="number">10.</span>, <span class="number">100</span>)</span><br><span class="line">x_data = tf.placeholder(shape=[<span class="number">1</span>], dtype=tf.float32)</span><br><span class="line">y_target = tf.placeholder(shape=[<span class="number">1</span>], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create variable (one model parameter = A)</span></span><br><span class="line">A = tf.Variable(tf.random_normal(shape=[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure></li></ul><ul><li>增加乘法操作：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add operation to graph</span></span><br><span class="line">my_output = tf.multiply(x_data, A)</span><br></pre></td></tr></table></figure></li></ul><ul><li>增加L2正则损失函数：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add L2 loss operation to graph</span></span><br><span class="line">loss = tf.square(my_output - y_target)</span><br></pre></td></tr></table></figure></li></ul><ul><li>在运行之前初始化变量：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Initialize variables</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br></pre></td></tr></table></figure></li></ul><ul><li>声明变量的优化器<br>大部分优化器算法需要知道每步迭代的步长，这距离是由学习率控制的。如果学习率太小，机器学习算法可能耗时很长才能收敛；如果学习率太大，机器学习算法可能会不收敛。相应地导致梯度消失和梯度爆炸等问题。学习率对算法的收敛影响较大。本次使用标准梯度下降法。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create Optimizer</span></span><br><span class="line">my_opt = tf.train.GradientDescentOptimizer(<span class="number">0.02</span>)</span><br><span class="line">train_step = my_opt.minimize(loss)</span><br></pre></td></tr></table></figure></li></ul><ul><li>训练算法<br>迭代101次，并且每25次迭代打印返回结果。选择一个随机的x和y，传入计算图中。TensorFlow将自动地计算损失，调整A偏差来最小化损失：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run Loop</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    rand_index = np.random.choice(<span class="number">100</span>)</span><br><span class="line">    rand_x = [x_vals[rand_index]]</span><br><span class="line">    rand_y = [y_vals[rand_index]]</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)</span><br><span class="line">    <span class="keyword">if</span> (i+<span class="number">1</span>)%<span class="number">25</span>==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'Step #'</span> + str(i+<span class="number">1</span>) + <span class="string">' A = '</span> + str(sess.run(A)))</span><br><span class="line">        print(<span class="string">'Loss = '</span> + str(sess.run(loss, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)))</span><br><span class="line"></span><br><span class="line">Here <span class="keyword">is</span> the output:</span><br><span class="line">Step <span class="comment">#25 A=[6.23402166]</span></span><br><span class="line">Loss=<span class="number">16.3173</span></span><br><span class="line">Step <span class="comment">#50 A=[8.50733757]</span></span><br><span class="line">Loss=<span class="number">3.56651</span></span><br><span class="line">Step <span class="comment">#75 A=[9.37753201]</span></span><br><span class="line">Loss=<span class="number">3.03149</span></span><br><span class="line">Step <span class="comment">#100 A=[9.80041122]</span></span><br><span class="line">Loss=<span class="number">0.0990248</span></span><br></pre></td></tr></table></figure></li></ul><ol start="2"><li>分类算法举例<br>先重置一下之前的TensorFlow计算图，就可以使用相同的TensorFlow脚本继续分类算法的例子。我们试图找到一个优化的转换方法A，它可以把两个正态分布转换到原点，sigmoid函数将正态分布分割成不同的两类。</li></ol><ul><li>重置计算图，并且重新初始化变量:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> ops</span><br><span class="line">ops.reset_default_graph()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create graph</span></span><br><span class="line">sess = tf.Session()</span><br></pre></td></tr></table></figure></li></ul><ul><li>从正态分布（N(-1,1)，N(3,1)）生成数据。同时也生成目标标签，占位符和偏差变量A：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create data</span></span><br><span class="line">x_vals = np.concatenate((np.random.normal(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">50</span>), np.random.normal(<span class="number">3</span>, <span class="number">1</span>, <span class="number">50</span>)))</span><br><span class="line">y_vals = np.concatenate((np.repeat(<span class="number">0.</span>, <span class="number">50</span>), np.repeat(<span class="number">1.</span>, <span class="number">50</span>)))</span><br><span class="line">x_data = tf.placeholder(shape=[<span class="number">1</span>], dtype=tf.float32)</span><br><span class="line">y_target = tf.placeholder(shape=[<span class="number">1</span>], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create variable (one model parameter = A)</span></span><br><span class="line">A = tf.Variable(tf.random_normal(mean=<span class="number">10</span>, shape=[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure></li></ul><ul><li>增加转换操作<br>这里不必封装sigmoid函数，因为损失函数中会实现此功能：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add operation to graph</span></span><br><span class="line"><span class="comment"># Want to create the operstion sigmoid(x + A)</span></span><br><span class="line"><span class="comment"># Note, the sigmoid() part is in the loss function</span></span><br><span class="line">my_output = tf.add(x_data, A)</span><br></pre></td></tr></table></figure></li></ul><ul><li>增加维度<br>由于指定的损失函数期望批量数据增加一个批量数的维度，使用expand_dims()函数增加维度：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Now we have to add another dimension to each (batch size of 1)</span></span><br><span class="line">my_output_expanded = tf.expand_dims(my_output, <span class="number">0</span>)</span><br><span class="line">y_target_expanded = tf.expand_dims(y_target, <span class="number">0</span>)</span><br></pre></td></tr></table></figure></li></ul><ul><li>初始化变量A：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Initialize variables</span></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line">sess.run(init)</span><br></pre></td></tr></table></figure></li></ul><ul><li>声明损失函数<br>这里使用一个带非归一化logits的交叉熵的损失函数，同时会用sigmoid函数转换。TensorFlow的nn.sigmoid_cross_entropy_with_logits()函数实现所有这些功能，需要向它传入指定的维度：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add classification loss (cross entropy)</span></span><br><span class="line">xentropy = tf.nn.sigmoid_cross_entropy_with_logits(my_output_expanded, y_target_expanded)</span><br></pre></td></tr></table></figure></li></ul><ul><li>增加一个优化器函数让TensorFlow知道如何更新和偏差变量：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create Optimizer</span></span><br><span class="line">my_opt = tf.train.GradientDescentOptimizer(<span class="number">0.05</span>)</span><br><span class="line">train_step = my_opt.minimize(xentropy)</span><br></pre></td></tr></table></figure></li></ul><ul><li>最后，通过随机选择的数据迭代几百次，相应地更新变量A。每迭代200次打印出损失和变量A的返回值：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run loop</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1400</span>):</span><br><span class="line">    rand_index = np.random.choice(<span class="number">100</span>)</span><br><span class="line">    rand_x = [x_vals[rand_index]]</span><br><span class="line">    rand_y = [y_vals[rand_index]]</span><br><span class="line">    </span><br><span class="line">    sess.run(train_step, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)</span><br><span class="line">    <span class="keyword">if</span> (i+<span class="number">1</span>)%<span class="number">200</span>==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'Step #'</span> + str(i+<span class="number">1</span>) + <span class="string">' A = '</span> + str(sess.run(A)))</span><br><span class="line">        print(<span class="string">'Loss = '</span> + str(sess.run(xentropy, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)))</span><br></pre></td></tr></table></figure></li></ul><p>Step #200 A=[3.59597969]<br>Loss=[[0.00126199]]<br>Step #400 A=[0.50947344]<br>Loss=[[0.01149425]]<br>Step #600 A=[-0.50994617]<br>Loss=[[0.14271219]]<br>Step #800 A=[-0.76606178]<br>Loss=[[0.18807337]]<br>Step #1000 A=[-0.90859312]<br>Loss=[[0.02346182]]<br>Step #1200 A=[-0.86169094]<br>Loss=[[0.05427232]]<br>Step #1400 A=[-1.08486211]<br>Loss=[[0.04099189]]</p><ol start="3"><li>总结</li></ol><ul><li>实现反向传播主要步骤：<ol><li>生成数据。</li><li>初始化占位符和变量。</li><li>创建损失函数。</li><li>定义一个优化器算法。</li><li>最后，通过随机数据样本进行迭代，更新变量。</li></ol></li></ul><ul><li>学习率选择方法：<br>|学习率|优缺点|使用场景|<br>|:-:|:-:|:-:|<br>|小学习率|收敛慢，但结果精确|若算法不稳定，先降低学习率|<br>|大学习率|结果不精确，但收敛快|若算法收敛太慢，可提高学习率|<br>有时，标准梯度下降算法会明显卡顿或者收敛变慢，特别是在梯度为0附近的点。为此，TensorFlow的MomentumOptimizer()函数增加了一项势能，前一次迭代过程的梯度下降值的倒数。<br>另一个可以改变的是优化器的步长。理想情况下，对于变化小的变量使用大步长；而变化迅速的变量使用小步长。实现这种优点的常用算法是Adagrad算法。此算法考虑整个历史迭代的变量梯度，TensorFlow中相应功能的实现是AdagradOptimizer()函数。<br>有时，由于Adagrad算法计算整个历史迭代的梯度，导致梯度迅速变为0.解决这个局限性的是Adadelta算法，它限制使用的迭代次数。TensorFlow中相应功能的实现是AdadeltaOptimizer()函数。</li></ul><h1 id="TensorFlow实现随机训练和批量训练"><a href="#TensorFlow实现随机训练和批量训练" class="headerlink" title="TensorFlow实现随机训练和批量训练"></a>TensorFlow实现随机训练和批量训练</h1><p>TensorFlow能一次操作一个数据点，也能一次操作大量数据。一个训练例子上的操作可能导致古怪的学习过程，但使用大批量的训练又会提高计算成本。随机训练会一次随机抽取训练数据和目标数据对完成训练。批量训练取平均损失来进行梯度计算，批量训练大小可以一次扩到整个数据集。扩展之前回归算法的例子——使用随机训练和批量训练。</p><ol><li><p>导入numpy、matplotlib和tensorflow模块，开始一个计算图会话：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">sess = tf.Session()</span><br></pre></td></tr></table></figure></li><li><p>声明批量大小<br>批量大小是指通过计算图一次传入多少训练数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">batch_size=<span class="number">20</span></span><br></pre></td></tr></table></figure></li><li><p>声明模型的数据，占位符和变量<br>占位符有两个维度：第一个维度为None，第二个维度是批量训练中的数据量。我们能显示地设置维度为20，也能设为None。必须知道训练模型中的维度，这会阻止不合法的矩阵操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create data</span></span><br><span class="line">x_vals = np.random.normal(<span class="number">1</span>, <span class="number">0.1</span>, <span class="number">100</span>)</span><br><span class="line">y_vals = np.repeat(<span class="number">10.</span>, <span class="number">100</span>)</span><br><span class="line">x_data = tf.placeholder(shape=[<span class="keyword">None</span>,<span class="number">1</span>], dtype=tf.float32)</span><br><span class="line">y_target = tf.placeholder(shape=[<span class="keyword">None</span>,<span class="number">1</span>], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create variable (one model parameter = A)</span></span><br><span class="line">A = tf.Variable(tf.random_normal(shape=[<span class="number">1</span>,<span class="number">1</span>]))</span><br></pre></td></tr></table></figure></li><li><p>在计算图中增加矩阵乘法操作<br>矩阵乘法不满足交换律，所以在matmul()函数中的矩阵参数顺序要正确：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add operation to graph</span></span><br><span class="line">my_output = tf.matmul(x_data, A)</span><br></pre></td></tr></table></figure></li><li><p>改变损失函数<br>批量训练时损失函数是每个数据点L2损失的平均值。在TensorFlow中通过reduce_mean()函数即可实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add L2 loss operation to graph</span></span><br><span class="line">loss = tf.reduce_mean(tf.square(my_output - y_target))</span><br></pre></td></tr></table></figure></li><li><p>声明优化器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create Optimizer</span></span><br><span class="line">my_opt = tf.train.GradientDescentOptimizer(<span class="number">0.02</span>)</span><br><span class="line">train_step = my_opt.minimize(loss)</span><br></pre></td></tr></table></figure></li><li><p>在训练中通过循环迭代优化模型算法<br>与之前不同，因为想绘制损失值图与随机训练对比，所以这里初始化一个列表每间隔5次迭代保存损失函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">loss_batch = []</span><br><span class="line"><span class="comment"># Run Loop</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    rand_index = np.random.choice(<span class="number">100</span>, size=batch_size)</span><br><span class="line">    rand_x = np.transpose([x_vals[rand_index]])</span><br><span class="line">    rand_y = np.transpose([y_vals[rand_index]])</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)</span><br><span class="line">    <span class="keyword">if</span> (i+<span class="number">1</span>)%<span class="number">5</span>==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'Step #'</span> + str(i+<span class="number">1</span>) + <span class="string">' A = '</span> + str(sess.run(A)))</span><br><span class="line">        temp_loss = sess.run(loss, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)</span><br><span class="line">        print(<span class="string">'Loss = '</span> + str(temp_loss))</span><br><span class="line">        loss_batch.append(temp_loss)</span><br></pre></td></tr></table></figure></li><li><p>迭代100次输出最终返回值。注意：A现在是二维矩阵。<br>Step #100 A=[[9.86720943]]<br>Loss=0</p></li><li><p>存储随机损失</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">loss_stochastic = []</span><br><span class="line"><span class="comment"># Run Loop</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    rand_index = np.random.choice(<span class="number">100</span>)</span><br><span class="line">    rand_x = [x_vals[rand_index]]</span><br><span class="line">    rand_y = [y_vals[rand_index]]</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)</span><br><span class="line">    <span class="keyword">if</span> (i+<span class="number">1</span>)%<span class="number">5</span>==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'Step #'</span> + str(i+<span class="number">1</span>) + <span class="string">' A = '</span> + str(sess.run(A)))</span><br><span class="line">        temp_loss = sess.run(loss, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)</span><br><span class="line">        print(<span class="string">'Loss = '</span> + str(temp_loss))</span><br><span class="line">        loss_stochastic.append(temp_loss)</span><br></pre></td></tr></table></figure></li><li><p>绘制回归算法的随机训练损失和批量训练损失：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(range(<span class="number">0</span>, <span class="number">100</span>, <span class="number">5</span>), loss_stochastic, <span class="string">'b-'</span>, label=<span class="string">'Stochastic Loss'</span>)</span><br><span class="line">plt.plot(range(<span class="number">0</span>, <span class="number">100</span>, <span class="number">5</span>), loss_batch, <span class="string">'r--'</span>, label=<span class="string">'Batch Loss, size=20'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'upper right'</span>, prop=&#123;<span class="string">'size'</span>: <span class="number">11</span>&#125;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></li></ol><p><img src="E:\hexo\source\_posts\TFML2\06_Back_Propagation.png" alt="avatar"></p><ol start="11"><li>总结<br>|训练类型|优点|缺点|<br>|:—–:|:–:|:—:|<br>|随机训练|脱离局部最小|一般需要多次迭代才收敛|<br>|批量训练|快速得到最小损失|耗费更多运算资源</li></ol><h1 id="TensorFlow实现创建分类器"><a href="#TensorFlow实现创建分类器" class="headerlink" title="TensorFlow实现创建分类器"></a>TensorFlow实现创建分类器</h1><p>在本节中，将结合之前的所有知识点创建一个iris数据集的分类器<br>加载iris样本数据集，实现一个简单的二值分类器来预测一朵花是否为山鸢尾。导入iris数据集和工具库，相应地对原数据集进行转换。</p><ol><li><p>导入相应地工具库，初始化计算图：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure></li><li><p>导入iris数据集，根据数据是否为山鸢尾将其转换成1或者0<br>由于iris数据集将山鸢尾标记为0，我们将其从0置为1，同时把其他物种标记为0。本次训练只使用两种特征：花瓣长度和花瓣宽度，这两个特征值在x-value的第三列和第四列：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">iris = datasets.load_iris()</span><br><span class="line">binary_target = np.array([<span class="number">1.</span> <span class="keyword">if</span> x==<span class="number">0</span> <span class="keyword">else</span> <span class="number">0.</span> <span class="keyword">for</span> x <span class="keyword">in</span> iris.target])</span><br><span class="line">iris_2d = np.array([[x[<span class="number">2</span>], x[<span class="number">3</span>]] <span class="keyword">for</span> x <span class="keyword">in</span> iris.data])</span><br></pre></td></tr></table></figure></li><li><p>声明批量训练大小、数据占位符和模型变量<br>注意，数据占位符的第一维度设为None：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Declare batch size</span></span><br><span class="line">batch_size = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create graph</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Declare placeholders</span></span><br><span class="line"><span class="comment">#通过指定dtype=tf.float32降低float的字节数，可以提高算法的性能</span></span><br><span class="line">x1_data = tf.placeholder(shape=[<span class="keyword">None</span>, <span class="number">1</span>], dtype=tf.float32)</span><br><span class="line">x2_data = tf.placeholder(shape=[<span class="keyword">None</span>, <span class="number">1</span>], dtype=tf.float32)</span><br><span class="line">y_target = tf.placeholder(shape=[<span class="keyword">None</span>, <span class="number">1</span>], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create variables A and b (0 = x1 - A*x2 + b)</span></span><br><span class="line">A = tf.Variable(tf.random_normal(shape=[<span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line">b = tf.Variable(tf.random_normal(shape=[<span class="number">1</span>, <span class="number">1</span>]))</span><br></pre></td></tr></table></figure></li><li><p>定义线性模型<br>线性模型的表达式为：x2=x1<em> A+b。如果找到的数据点在直线以上，则将数据点代入x2-x1</em>A-b计算出的结果大于0；同理，找到的数据点在直线以下，则将数据点代入x2-x1 <em> A-b计算出的结果小于0。将公式x2-x1 </em> A-b传入sigmoid函数，然后预测结果1或者0。TensorFlow有内建的sigmoid损失函数，所以仅仅需要定义模型输出即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add model to graph:</span></span><br><span class="line"><span class="comment"># x1 - A*x2 + b</span></span><br><span class="line">my_mult = tf.matmul(x2_data, A)</span><br><span class="line">my_add = tf.add(my_mult, b)</span><br><span class="line">my_output = tf.sub(x1_data, my_add)</span><br></pre></td></tr></table></figure></li><li><p>增加sigmoid交叉熵损失函数<br>TensorFlow的sigmoid交叉熵损失函数是sigmoid_cross_entropy_with_logits()：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add classification loss (cross entropy)</span></span><br><span class="line">xentropy = tf.nn.sigmoid_cross_entropy_with_logits(my_output, y_target)</span><br></pre></td></tr></table></figure></li><li><p>声明优化器方法，最小化交叉熵损失<br>选择学习率为0.05：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create Optimizer</span></span><br><span class="line">my_opt = tf.train.GradientDescentOptimizer(<span class="number">0.05</span>)</span><br><span class="line">train_step = my_opt.minimize(xentropy)</span><br></pre></td></tr></table></figure></li><li><p>创建一个变量初始化操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Initialize variables</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br></pre></td></tr></table></figure></li><li><p>迭代100次训练线性模型<br>传入三种数据：花瓣长度、花瓣宽度和目标变量，每200次迭代打印出变量值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run Loop</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    rand_index = np.random.choice(len(iris_2d), size=batch_size)</span><br><span class="line">    <span class="comment">#rand_x = np.transpose([iris_2d[rand_index]])</span></span><br><span class="line">    rand_x = iris_2d[rand_index]</span><br><span class="line">    rand_x1 = np.array([[x[<span class="number">0</span>]] <span class="keyword">for</span> x <span class="keyword">in</span> rand_x])</span><br><span class="line">    rand_x2 = np.array([[x[<span class="number">1</span>]] <span class="keyword">for</span> x <span class="keyword">in</span> rand_x])</span><br><span class="line">    <span class="comment">#rand_y = np.transpose([binary_target[rand_index]])</span></span><br><span class="line">    rand_y = np.array([[y] <span class="keyword">for</span> y <span class="keyword">in</span> binary_target[rand_index]])</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;x1_data: rand_x1, x2_data: rand_x2, y_target: rand_y&#125;)</span><br><span class="line">    <span class="keyword">if</span> (i+<span class="number">1</span>)%<span class="number">200</span>==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'Step #'</span> + str(i+<span class="number">1</span>) + <span class="string">' A = '</span> + str(sess.run(A)) + <span class="string">', b = '</span> + str(sess.run(b)))</span><br></pre></td></tr></table></figure></li><li><p>抽取模型变量并绘图：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Visualize Results</span></span><br><span class="line"><span class="comment"># Pull out slope/intercept</span></span><br><span class="line">[[slope]] = sess.run(A)</span><br><span class="line">[[intercept]] = sess.run(b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create fitted line</span></span><br><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">3</span>, num=<span class="number">50</span>)</span><br><span class="line">ablineValues = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> x:</span><br><span class="line">  ablineValues.append(slope*i+intercept)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot the fitted line over the data</span></span><br><span class="line">setosa_x = [a[<span class="number">1</span>] <span class="keyword">for</span> i,a <span class="keyword">in</span> enumerate(iris_2d) <span class="keyword">if</span> binary_target[i]==<span class="number">1</span>]</span><br><span class="line">setosa_y = [a[<span class="number">0</span>] <span class="keyword">for</span> i,a <span class="keyword">in</span> enumerate(iris_2d) <span class="keyword">if</span> binary_target[i]==<span class="number">1</span>]</span><br><span class="line">non_setosa_x = [a[<span class="number">1</span>] <span class="keyword">for</span> i,a <span class="keyword">in</span> enumerate(iris_2d) <span class="keyword">if</span> binary_target[i]==<span class="number">0</span>]</span><br><span class="line">non_setosa_y = [a[<span class="number">0</span>] <span class="keyword">for</span> i,a <span class="keyword">in</span> enumerate(iris_2d) <span class="keyword">if</span> binary_target[i]==<span class="number">0</span>]</span><br><span class="line">plt.plot(setosa_x, setosa_y, <span class="string">'rx'</span>, ms=<span class="number">10</span>, mew=<span class="number">2</span>, label=<span class="string">'setosa'</span>)</span><br><span class="line">plt.plot(non_setosa_x, non_setosa_y, <span class="string">'ro'</span>, label=<span class="string">'Non-setosa'</span>)</span><br><span class="line">plt.plot(x, ablineValues, <span class="string">'b-'</span>)</span><br><span class="line">plt.xlim([<span class="number">0.0</span>, <span class="number">2.7</span>])</span><br><span class="line">plt.ylim([<span class="number">0.0</span>, <span class="number">7.1</span>])</span><br><span class="line">plt.suptitle(<span class="string">'Linear Separator For I.setosa'</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Petal Length'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Petal Width'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'lower right'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></li></ol><p><img src="E:\hexo\source\_posts\TFML2\07_Combing_Everything_Together.png" alt="avatar"></p><h1 id="TensorFlow实现模型评估"><a href="#TensorFlow实现模型评估" class="headerlink" title="TensorFlow实现模型评估"></a>TensorFlow实现模型评估</h1><p>使用TensorFlow时，需要把模型评估加入到计算图中，然后在模型训练完后调用模型评估。在训练模型评估中，模型评估能洞察模型算法，给出提示信息来调试、提高或者改变整个模型。但是在模型训练中并不是总需要模型评估。训练模型之后，需要定量评估模型的性能如何。在理想情况下，评估模型需要一个训练数据集和测试数据集，有时甚至需要一个验证数据集。<br>想评估一个模型时就得使用大批量数据点。如果完成批量训练，我们可以重用模型来预测批量数据点。但是如果要完成随机训练，就需要创建单独的评估器来处理批量数据点。<br>回归算法模型用来预测连续数值型，其目标不是分类值而是数字。为了评估这些回归预测值是否与实际目标相符，我们需要度量两者间的距离。<br>分类算法模型基于数值型输入预测分类值，实际目标值是1和0的序列。我们需要度量预测值与真实值之间的距离。分类算法模型的损失函数一般不容易解释模型好坏，所以通常情况是看准确预测分类的结果的百分比。</p><ul><li><p>评估回归算法模型，其拟合常数乘法，目标值是10，步骤如下：</p><ol><li><p>加载所需的编程库，创建计算图、数据集、变量和占位符<br>创建完数据后，将它们随机分割成训练数据集和测试数据集。不管算法模型预测的如何，都需要测试算法模型。在训练数据和测试数据上都进行模型评估，以搞清楚模型是否过拟合：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create graph</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"><span class="comment"># Create data</span></span><br><span class="line">x_vals = np.random.normal(<span class="number">1</span>, <span class="number">0.1</span>, <span class="number">100</span>)</span><br><span class="line">y_vals = np.repeat(<span class="number">10.</span>, <span class="number">100</span>)</span><br><span class="line">x_data = tf.placeholder(shape=[<span class="keyword">None</span>, <span class="number">1</span>], dtype=tf.float32)</span><br><span class="line">y_target = tf.placeholder(shape=[<span class="keyword">None</span>, <span class="number">1</span>], dtype=tf.float32)</span><br><span class="line">batch_size = <span class="number">25</span></span><br><span class="line"><span class="comment"># Split data into train/test = 80%/20%</span></span><br><span class="line">train_indices = np.random.choice(len(x_vals), round(len(x_vals)*<span class="number">0.8</span>), replace=<span class="keyword">False</span>)</span><br><span class="line">test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))</span><br><span class="line">x_vals_train = x_vals[train_indices]</span><br><span class="line">x_vals_test = x_vals[test_indices]</span><br><span class="line">y_vals_train = y_vals[train_indices]</span><br><span class="line">y_vals_test = y_vals[test_indices]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create variable (one model parameter = A)</span></span><br><span class="line">A = tf.Variable(tf.random_normal(shape=[<span class="number">1</span>,<span class="number">1</span>]))</span><br></pre></td></tr></table></figure></li><li><p>声明算法模型、损失函数和优化器算法<br>初始化模型变量A，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add operation to graph</span></span><br><span class="line">my_output = tf.matmul(x_data, A)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add L2 loss operation to graph</span></span><br><span class="line">loss = tf.reduce_mean(tf.square(my_output - y_target))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize variables</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create Optimizer</span></span><br><span class="line">my_opt = tf.train.GradientDescentOptimizer(<span class="number">0.02</span>)</span><br><span class="line">train_step = my_opt.minimize(loss)</span><br></pre></td></tr></table></figure></li><li><p>迭代训练模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run Loop</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    rand_index = np.random.choice(len(x_vals_train), size=batch_size)</span><br><span class="line">    rand_x = np.transpose([x_vals_train[rand_index]])</span><br><span class="line">    rand_y = np.transpose([y_vals_train[rand_index]])</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)</span><br><span class="line">    <span class="keyword">if</span> (i+<span class="number">1</span>)%<span class="number">25</span>==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'Step #'</span> + str(i+<span class="number">1</span>) + <span class="string">' A = '</span> + str(sess.run(A)))</span><br><span class="line">        print(<span class="string">'Loss = '</span> + str(sess.run(loss, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)))</span><br></pre></td></tr></table></figure><p>输出：<br>Step #25 A=[[6.39879179]]<br>Loss=13.7903<br>Step #50 A=[[8.64770794]]<br>Loss=2.53685<br>Step #75 A=[[9.40029907]]<br>Loss=0.818259<br>Step #100 A=[[9.6809473]]<br>Loss=1.10908</p></li><li><p>为了评估训练模型，打印出训练数据集和测试数据集训练的MSE损失函数值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Evaluate accuracy (loss) on test set</span></span><br><span class="line">mse_test = sess.run(loss, feed_dict=&#123;x_data: np.transpose([x_vals_test]), y_target: np.transpose([y_vals_test])&#125;)</span><br><span class="line">mse_train = sess.run(loss, feed_dict=&#123;x_data: np.transpose([x_vals_train]), y_target: np.transpose([y_vals_train])&#125;)</span><br><span class="line">print(<span class="string">'MSE on test:'</span> + str(np.round(mse_test, <span class="number">2</span>)))</span><br><span class="line">print(<span class="string">'MSE on train:'</span> + str(np.round(mse_train, <span class="number">2</span>)))</span><br></pre></td></tr></table></figure><p>输出：<br>MSE on test:1.35<br>MSE on train:0.88</p></li></ol></li></ul><ul><li><p>评估分类算法模型。创建准确率函数（accuracy function），分别调用sigmoid来测试分类是否正确</p><ol><li><p>重新加载计算图，创建数据集、变量和占位符。<br>分割数据集和目标成为训练集和测试集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> ops</span><br><span class="line">ops.reset_default_graph()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create graph</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Declare batch size</span></span><br><span class="line">batch_size = <span class="number">25</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create data</span></span><br><span class="line">x_vals = np.concatenate((np.random.normal(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">50</span>), np.random.normal(<span class="number">2</span>, <span class="number">1</span>, <span class="number">50</span>)))</span><br><span class="line">y_vals = np.concatenate((np.repeat(<span class="number">0.</span>, <span class="number">50</span>), np.repeat(<span class="number">1.</span>, <span class="number">50</span>)))</span><br><span class="line">x_data = tf.placeholder(shape=[<span class="number">1</span>, <span class="keyword">None</span>], dtype=tf.float32)</span><br><span class="line">y_target = tf.placeholder(shape=[<span class="number">1</span>, <span class="keyword">None</span>], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split data into train/test = 80%/20%</span></span><br><span class="line">train_indices = np.random.choice(len(x_vals), round(len(x_vals)*<span class="number">0.8</span>), replace=<span class="keyword">False</span>)</span><br><span class="line">test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))</span><br><span class="line">x_vals_train = x_vals[train_indices]</span><br><span class="line">x_vals_test = x_vals[test_indices]</span><br><span class="line">y_vals_train = y_vals[train_indices]</span><br><span class="line">y_vals_test = y_vals[test_indices]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create variable (one model parameter = A)</span></span><br><span class="line">A = tf.Variable(tf.random_normal(mean=<span class="number">10</span>, shape=[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure></li><li><p>在计算图中，增加模型和损失函数，初始化变量，并创建优化器：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add operation to graph</span></span><br><span class="line"><span class="comment"># Want to create the operstion sigmoid(x + A)</span></span><br><span class="line"><span class="comment"># Note, the sigmoid() part is in the loss function</span></span><br><span class="line">my_output = tf.add(x_data, A)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize variables</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add classification loss (cross entropy)</span></span><br><span class="line">xentropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(my_output, y_target))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create Optimizer</span></span><br><span class="line">my_opt = tf.train.GradientDescentOptimizer(<span class="number">0.05</span>)</span><br><span class="line">train_step = my_opt.minimize(xentropy)</span><br></pre></td></tr></table></figure></li><li><p>进行迭代训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run loop</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1800</span>):</span><br><span class="line">    rand_index = np.random.choice(len(x_vals_train), size=batch_size)</span><br><span class="line">    rand_x = [x_vals_train[rand_index]]</span><br><span class="line">    rand_y = [y_vals_train[rand_index]]</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)</span><br><span class="line">    <span class="keyword">if</span> (i+<span class="number">1</span>)%<span class="number">200</span>==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'Step #'</span> + str(i+<span class="number">1</span>) + <span class="string">' A = '</span> + str(sess.run(A)))</span><br><span class="line">        print(<span class="string">'Loss = '</span> + str(sess.run(xentropy, feed_dict=&#123;x_data: rand_x, y_target: rand_y&#125;)))</span><br></pre></td></tr></table></figure><p>输出：<br>Step #200 A=[6.64970636]<br>Loss=3.39434<br>Step #400 A=[2.2884655]<br>Loss=0.456173<br>Step #600 A=[0.29109824]<br>Loss=0.312162<br>Step #800 A=[-0.20045301]<br>Loss=0.241349<br>Step #1000 A=[-0.33634067]<br>Loss=0.376786<br>Step #1200 A=[-0.36866501]<br>Loss=0.271654<br>Step #1400 A=[-0.3727718]<br>Loss=0.294866<br>Step #1600 A=[-0.39153299]<br>Loss=0.202275<br>Step #1800 A=[-0.36630616]<br>Loss=0.358463</p></li><li><p>评估训练模型<br>为了评估训练模型，创建预测操作。用squeeze()函数封装预测操作，使得预测值和目标值有相同的维度。然后用equal()函数检测是否相等，把得到的true或false的boolean型张量转化成float32型，再对其取平均值，得到一个准确度值。用这个函数评估训练模型和测试模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Evaluate Predictions on test set</span></span><br><span class="line">y_prediction = tf.squeeze(tf.round(tf.nn.sigmoid(tf.add(x_data, A))))</span><br><span class="line">correct_prediction = tf.equal(y_prediction, y_target)</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">acc_value_test = sess.run(accuracy, feed_dict=&#123;x_data: [x_vals_test], y_target: [y_vals_test]&#125;)</span><br><span class="line">acc_value_train = sess.run(accuracy, feed_dict=&#123;x_data: [x_vals_train], y_target: [y_vals_train]&#125;)</span><br><span class="line">print(<span class="string">'Accuracy on train set: '</span> + str(acc_value_train))</span><br><span class="line">print(<span class="string">'Accuracy on test set: '</span> + str(acc_value_test))</span><br></pre></td></tr></table></figure><p>输出：<br>Accuracy on train set: 0.925<br>Accuracy on test set: 0.95</p></li></ol></li></ul><ul><li>绘制模型和数据点<br>模型训练结果，比如准确度、MSE等，将帮助我们评估机器学习模型。因为这是一个一维模型，能很容易地绘制模型和数据点。用matplotlib绘制两个分开的直方图来可视化机器学习模型和数据点：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Plot classification result</span></span><br><span class="line">A_result = -sess.run(A)</span><br><span class="line">bins = np.linspace(<span class="number">-5</span>, <span class="number">5</span>, <span class="number">50</span>)</span><br><span class="line">plt.hist(x_vals[<span class="number">0</span>:<span class="number">50</span>], bins, alpha=<span class="number">0.5</span>, label=<span class="string">'N(-1,1)'</span>, color=<span class="string">'blue'</span>)</span><br><span class="line">plt.hist(x_vals[<span class="number">50</span>:<span class="number">100</span>], bins[<span class="number">0</span>:<span class="number">50</span>], alpha=<span class="number">0.5</span>, label=<span class="string">'N(2,1)'</span>, color=<span class="string">'red'</span>)</span><br><span class="line">plt.plot((A_result, A_result), (<span class="number">0</span>, <span class="number">8</span>), <span class="string">'k--'</span>, linewidth=<span class="number">3</span>, label=<span class="string">'A = '</span>+ str(np.round(A_result, <span class="number">2</span>)))</span><br><span class="line">plt.legend(loc=<span class="string">'upper right'</span>)</span><br><span class="line">plt.title(<span class="string">'Binary Classifier, Accuracy='</span> + str(np.round(acc_value_test, <span class="number">2</span>)))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></li></ul><p><img src="E:\hexo\source\_posts\TFML2\08_Evaluating_Models.png" alt="Avatar"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;计算图中的操作&quot;&gt;&lt;a href=&quot;#计算图中的操作&quot; class=&quot;headerlink&quot; title=&quot;计算图中的操作&quot;&gt;&lt;/a&gt;计算图中的操作&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class
      
    
    </summary>
    
      <category term="学习笔记" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>前端招聘题集（1）</title>
    <link href="http://yoursite.com/2018/04/21/front-end-interview-1/"/>
    <id>http://yoursite.com/2018/04/21/front-end-interview-1/</id>
    <published>2018-04-21T09:58:01.000Z</published>
    <updated>2018-04-21T13:37:51.100Z</updated>
    
    <content type="html"><![CDATA[<h1 id="2018-3美团春招面试（答案待更新）"><a href="#2018-3美团春招面试（答案待更新）" class="headerlink" title="2018.3美团春招面试（答案待更新）"></a>2018.3美团春招面试（答案待更新）</h1><ol><li>cookie的使用</li><li>koa中间件实现原理</li><li>描述快速排序的实现</li><li>原型链相关问题</li><li>react生命周期</li><li>react性能优化</li><li>vue双面绑定原理</li><li>如何用js实现动画</li><li>css动画性能以及与js动画性能比较</li><li>二叉树</li><li>二叉树后序排序</li><li>模板引擎实现原理</li><li>怎么做同构以及同构的两份代码的差异性</li><li>koa中间件执行顺序以及如何实现</li><li>跨域问题</li><li>jsonp的原理以及优缺点</li><li>jquery和vue性能比较以及使用场景</li><li>什么是高阶组件</li><li>假设我维护一个服务端渲染框架，如何不侵入用户代码的情况下通知用户代码错误点（开放题）</li><li>js bridge原理</li><li>https和http的不同之处</li><li>http2.0的特性</li><li>如何实现一个promise</li><li>用node.js做过什么</li><li>graghQL和RESTful api</li></ol><h1 id="2018-4腾讯春招面试"><a href="#2018-4腾讯春招面试" class="headerlink" title="2018.4腾讯春招面试"></a>2018.4腾讯春招面试</h1><ol><li><p>node.js如何开启一个http服务</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//引入内置http模块</span></span><br><span class="line"><span class="keyword">var</span> http=<span class="built_in">require</span>(<span class="string">'http'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建一个简单的服务器，访问http://127.0.0.1:1337/，显示Hello World</span></span><br><span class="line">http.createServer(<span class="function"><span class="keyword">function</span>(<span class="params">req,res</span>)</span>&#123;</span><br><span class="line">    res.writeHead(<span class="number">200</span>,&#123;<span class="string">'Content-Type'</span>:<span class="string">'text/plain'</span>&#125;);</span><br><span class="line">    res.end(<span class="string">'Hello World\n'</span>);</span><br><span class="line">&#125;).listen(<span class="number">1337</span>,<span class="string">'127.0.0.1'</span>);</span><br><span class="line"><span class="built_in">console</span>.log(<span class="string">'Server running at http://127.0.0.1:137'</span>);</span><br></pre></td></tr></table></figure></li><li><p>CSS3动画的实现方式有哪些？动手写一下将一个div在1s内移动300px<br>transition方式：过渡动画，只定义初始和最终状态；<br>animation方式：可以逐帧设置</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"utf-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">"viewport"</span> <span class="attr">content</span>=<span class="string">"width=device-width,initial-scale=1.0"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">http-equiv</span>=<span class="string">"X-UA-Compatible"</span> <span class="attr">content</span>=<span class="string">"ie=edge"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Document<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">style</span> <span class="attr">type</span>=<span class="string">"text/css"</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined">        /*transition属性动画结合transform变化属性，实现元素移动一段距离的动画*/</span></span><br><span class="line"><span class="undefined">        #transitionDiv:hover&#123;</span></span><br><span class="line"><span class="undefined">            transition:all 1s ease-in-out;</span></span><br><span class="line"><span class="undefined">            -webkit-transition:all 1s ease-in-out;</span></span><br><span class="line"><span class="undefined">            -moz-transition:all 1s ease-in-out;</span></span><br><span class="line"><span class="undefined">            -o-transition:all 1s ease-in-out;</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">            transform:translateX(300px);</span></span><br><span class="line"><span class="undefined">            -ms-transform:translateX(300px);</span></span><br><span class="line"><span class="undefined">            -moz-transform:translateX(300px);</span></span><br><span class="line"><span class="undefined">            -webkit-transform:translateX(300px);</span></span><br><span class="line"><span class="undefined">            -o-transform:translateX(300px);</span></span><br><span class="line"><span class="undefined">        &#125;</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">        /*通过animation属性，实现逐帧动画*/</span></span><br><span class="line"><span class="undefined">        #animationDiv:hover&#123;</span></span><br><span class="line"><span class="undefined">            animation:animName 1s ease-in-out;</span></span><br><span class="line"><span class="undefined">            -webkit-animation:animName 1s ease-in-out;</span></span><br><span class="line"><span class="undefined">            -moz-animation:animName 1s ease-in-out;</span></span><br><span class="line"><span class="undefined">            -o-animation:animName 1s ease-in-out;</span></span><br><span class="line"><span class="undefined">        &#125;</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">        /*定义关键帧*/</span></span><br><span class="line"><span class="undefined">        @keyframes animName&#123;</span></span><br><span class="line"><span class="undefined">            0%&#123;</span></span><br><span class="line"><span class="undefined">                transform:translateX(0px);</span></span><br><span class="line"><span class="undefined">            &#125;</span></span><br><span class="line"><span class="undefined">            30%&#123;</span></span><br><span class="line"><span class="undefined">                transform:translateX(100px);</span></span><br><span class="line"><span class="undefined">            &#125;</span></span><br><span class="line"><span class="undefined">            60%&#123;</span></span><br><span class="line"><span class="undefined">                transform:translateX(200px);</span></span><br><span class="line"><span class="undefined">            &#125;</span></span><br><span class="line"><span class="undefined">            100%&#123;</span></span><br><span class="line"><span class="undefined">                transform:translateX(300px);</span></span><br><span class="line"><span class="undefined">            &#125;</span></span><br><span class="line"><span class="undefined">        &#125;</span></span><br><span class="line"><span class="undefined">    </span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"transitionDiv"</span> <span class="attr">style</span>=<span class="string">"width:40px;height:40px;background-color:red;"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"animationDiv"</span> <span class="attr">style</span>=<span class="string">"width:40px;height:40px;background-color:green;"</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>DNS解析过程？若是新申请的域名如何查找DNS？<br>DNS是应用层协议，事实上他是为其他应用层协议工作的，包括不限于HTTP和SMTP以及FTP，用于将用户提供的主机名解析为ip地址。<br>具体过程如下：</p></li></ol><ul><li>浏览器缓存: 当用户通过浏览器访问某域名时，浏览器首先会在自己的缓存中查找是否有该域名对应的IP地址（若曾经访问过该域名且没有清空缓存便存在)；</li></ul><ul><li>系统缓存： 当浏览器缓存中无域名对应IP则会自动检查用户计算机系统Hosts文件DNS缓存是否有该域名对应IP；</li></ul><ul><li>路由器缓存: 当浏览器及系统缓存中均无域名对应IP则进入路由器缓存中检查，以上三步均为客户端的DNS缓存；</li></ul><ul><li>ISP（互联网服务提供商）DNS缓存: 当在用户客服端查找不到域名对应IP地址，则将进入ISP DNS缓存中进行查询。比如你用的是电信的网络，则会进入电信的DNS缓存服务器中进行查找；(或者向网络设置中指定的local DNS进行查询，如果在PC指定了DNS的话，如果没有设置比如DNS动态获取，则向ISP DNS发起查询请求)</li></ul><ul><li>根域名服务器: 当以上均未完成，则进入根服务器进行查询。全球仅有13台根域名服务器，1个主根域名服务器，其余12为辅根域名服务器。根域名收到请求后会查看区域文件记录，若无则将其管辖范围内顶级域名（如.com）服务器IP告诉本地DNS服务器；</li></ul><ul><li>顶级域名服务器: 顶级域名服务器收到请求后查看区域文件记录，若无则将其管辖范围内主域名服务器的IP地址告诉本地DNS服务器；</li></ul><ul><li>主域名服务器: 主域名服务器接受到请求后查询自己的缓存，如果没有则进入下一级域名服务器进行查找，并重复该步骤直至找到正确记录；</li></ul><ul><li>保存结果至缓存: 本地域名服务器把返回的结果保存到缓存，以备下一次使用，同时将该结果反馈给客户端，客户端通过这个IP地址与web服务器建立链接。</li></ul><ol start="4"><li>Ajax请求状态以及意义<br>在javascript里面写AJax的时，最关键的一步是对XMLHttpRequest对象建立监听，即使用“onreadystatechange”方法。监听的时候，要对XMLHttpRequest对象的请求状态进行判断，通常是判断readyState的值为4且http返回状态status的值为200或者304时执行我们需要的操作。<br>readyState属性表示Ajax请求的当前状态。<br>0 代表未初始化。还没有调用open方法<br>1 代表正在加载。open 方法已被调用，但send方法还没有被调用<br>2 代表已加载完毕。send已被调用。请求已经开始<br>3 代表交互中。服务器正在发送响应<br>4 代表完成。响应发送完毕</li><li>cookie的操作，读写<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">(<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line"> <span class="keyword">var</span> cookieObj = &#123;</span><br><span class="line">    <span class="comment">//修改或是添加cookie</span></span><br><span class="line">   <span class="string">'add'</span>: <span class="function"><span class="keyword">function</span>(<span class="params">name, value, hours</span>) </span>&#123; </span><br><span class="line">        <span class="keyword">var</span> expire = <span class="string">""</span>;</span><br><span class="line">        <span class="keyword">if</span>(hours != <span class="literal">null</span>)&#123;</span><br><span class="line">            expire = <span class="keyword">new</span> <span class="built_in">Date</span>((<span class="keyword">new</span> <span class="built_in">Date</span>()).getTime() + hours * <span class="number">3600000</span>);</span><br><span class="line">            expire = <span class="string">"; expires="</span> + expire.toGMTString();</span><br><span class="line">        &#125;    </span><br><span class="line">    <span class="built_in">document</span>.cookie = name + <span class="string">"="</span> + <span class="built_in">escape</span>(value) + expire + <span class="string">";path=/"</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//如果指定域名可以使用如下</span></span><br><span class="line">    <span class="comment">//document.cookie = name + "=" + escape(value) + expire + ";path=/;domain=findme.wang";</span></span><br><span class="line">   &#125;,</span><br><span class="line">   </span><br><span class="line">   <span class="comment">//读取cookie</span></span><br><span class="line">   <span class="string">'get'</span>: <span class="function"><span class="keyword">function</span>(<span class="params">c_name</span>)</span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">document</span>.cookie.length&gt;<span class="number">0</span>) &#123;</span><br><span class="line">            c_start = <span class="built_in">document</span>.cookie.indexOf(c_name + <span class="string">"="</span>);</span><br><span class="line">            <span class="keyword">if</span> (c_start != <span class="number">-1</span>) &#123; </span><br><span class="line">                c_start=c_start + c_name.length+<span class="number">1</span>;</span><br><span class="line">                c_end=<span class="built_in">document</span>.cookie.indexOf(<span class="string">";"</span>,c_start);</span><br><span class="line">                <span class="keyword">if</span> (c_end == <span class="number">-1</span>) &#123;</span><br><span class="line">                    c_end = <span class="built_in">document</span>.cookie.length;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> <span class="built_in">unescape</span>(<span class="built_in">document</span>.cookie.substring(c_start,c_end));</span><br><span class="line">            &#125; </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">""</span>;</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;;</span><br><span class="line"> <span class="built_in">window</span>.cookieObj=cookieObj;</span><br><span class="line">&#125;());</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;2018-3美团春招面试（答案待更新）&quot;&gt;&lt;a href=&quot;#2018-3美团春招面试（答案待更新）&quot; class=&quot;headerlink&quot; title=&quot;2018.3美团春招面试（答案待更新）&quot;&gt;&lt;/a&gt;2018.3美团春招面试（答案待更新）&lt;/h1&gt;&lt;ol&gt;

      
    
    </summary>
    
      <category term="招聘试题" scheme="http://yoursite.com/categories/%E6%8B%9B%E8%81%98%E8%AF%95%E9%A2%98/"/>
    
    
      <category term="JavaScript" scheme="http://yoursite.com/tags/JavaScript/"/>
    
      <category term="前端" scheme="http://yoursite.com/tags/%E5%89%8D%E7%AB%AF/"/>
    
      <category term="HTML" scheme="http://yoursite.com/tags/HTML/"/>
    
      <category term="CSS" scheme="http://yoursite.com/tags/CSS/"/>
    
      <category term="web" scheme="http://yoursite.com/tags/web/"/>
    
  </entry>
  
  <entry>
    <title>TFMLC学习笔记（1） TensorFlow基础</title>
    <link href="http://yoursite.com/2018/04/20/TFMLC-1/"/>
    <id>http://yoursite.com/2018/04/20/TFMLC-1/</id>
    <published>2018-04-19T18:41:11.000Z</published>
    <updated>2018-04-20T18:06:15.582Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TensorFlow算法的一般流程"><a href="#TensorFlow算法的一般流程" class="headerlink" title="TensorFlow算法的一般流程"></a>TensorFlow算法的一般流程</h1><ol><li>导入/生成样本数据集</li><li>转换和归一化数据</li></ol><ul><li>归一化函数如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data=tf.nn.batch_norm_with_global_normalization(...)</span><br></pre></td></tr></table></figure></li></ul><ol start="3"><li>将样本数据集划为三块：训练样本集、测试样本集、验证样本集<br> 训练集和测试集要不同；用验证集决定最优的超参数</li><li>设置机器学习参数（超参数）</li></ol><ul><li>经常一次性初始化所有的机器学习参数，例如：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">learning_rate=<span class="number">0.01</span></span><br><span class="line">batch_size=<span class="number">100</span></span><br><span class="line">iterations=<span class="number">1000</span></span><br></pre></td></tr></table></figure></li></ul><ol start="5"><li>初始化变量和占位符</li></ol><ul><li>在求解最优化工程中（最小化损失函数），TensorFlow使用占位符获取数据，并调整变量和权重/偏差；</li></ul><ul><li>TensorFlow指定数据大小和数据类型化初始化变量和占位符；</li></ul><ul><li>使用的数据类型字节数越多，结果越精确，运行速度也越慢；<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a_var=tf.constant(<span class="number">42</span>)</span><br><span class="line">x_input=tf.placeholder(tf.float32,[<span class="keyword">None</span>,input_size])</span><br><span class="line">y_input=tf.placeholder(tf.float32,[<span class="keyword">None</span>,num_classes])</span><br></pre></td></tr></table></figure></li></ul><ol start="6"><li>定义模型结构</li></ol><ul><li>一个简单的线性模型：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y_pred=tf.add(tf.mul(x_input,weight_matrix),b_matrix)</span><br></pre></td></tr></table></figure></li></ul><ol start="7"><li>声明损失函数</li></ol><ul><li>损失函数说明预测值与实际值之间的差距:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss=tf.reduce_mean(tf.square(y_actual-y_pred))</span><br></pre></td></tr></table></figure></li></ul><ol start="8"><li>初始化模型和训练模型</li></ol><ul><li>TensorFlow创建计算图实例，通过占位符赋值，维护变量的状态信息</li><li><p>初始化计算图的一种方式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session(graph=graph) <span class="keyword">as</span> session:</span><br><span class="line">...</span><br><span class="line">session.run(...)</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li><li><p>初始化计算图的另一种方式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">session=tf.Session(graph=graph)</span><br><span class="line">session.run(...)</span><br></pre></td></tr></table></figure></li></ul><ol start="9"><li>评估机器学习模型</li><li>调优超参数</li><li>发布/预测结果</li></ol><h1 id="声明张量"><a href="#声明张量" class="headerlink" title="声明张量"></a>声明张量</h1><p>TensorFlow主要的数据结构就是张量，它用张量来操作计算图。可以把变量或者占位符声明为张量。</p><ol><li>创建张量</li></ol><ul><li><p>固定张量</p><ul><li>创建指定维度的零张量：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zero_tsr=tf.zeros([row_dim,col_dim])</span><br></pre></td></tr></table></figure></li></ul><ul><li>创建指定维度的单位张量：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ones_tsr=tf.ones([row_dim,col_dim])</span><br></pre></td></tr></table></figure></li></ul><ul><li>创建指定维度的常数填充的张量：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">filled_tsr=tf.fill([row_dim,col_dim],<span class="number">42</span>)</span><br></pre></td></tr></table></figure></li></ul><ul><li>用已知常数张量创建一个张量:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">constant_tsr=tf.constant([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br></pre></td></tr></table></figure></li></ul><ul><li>tf.constant()函数也可以广播一个值为数组，然后模拟tf.fill()函数的功能：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.constant(<span class="number">42</span>,[row_dim,col_dim])</span><br></pre></td></tr></table></figure></li></ul></li></ul><ul><li>相似形状的张量<br>  新建一个与给定的tensor类型大小一致的tensor，其所有元素为0或1：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zeros_similar=tf.zeros_like(constant_tsr)</span><br><span class="line">ones_similar=tf.ones_like(contant_tsr)</span><br></pre></td></tr></table></figure></li></ul><ul><li>序列张量<br>  TensorFlow可以创建指定间隔的张量，以下函数的输出与range()函数和numpy中的linspace()函数的输出相似：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">linear_tsr=tf.linspace(start=<span class="number">0</span>,stop=<span class="number">1</span>,start=<span class="number">3</span>)          <span class="comment">#返回张量：[0.0,0.5,1.0]序列</span></span><br><span class="line">integer_seq_tsr=tf.range(start=<span class="number">6</span>,limit=<span class="number">15</span>,delta=<span class="number">3</span>)      <span class="comment">#返回张量：[6,9,12]序列</span></span><br></pre></td></tr></table></figure></li></ul><ul><li><p>随机张量</p><ul><li><p>tf.randon_uniform()生成均匀分布的随机数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">randunif_tsr=tf.random_uniform([row_dim,col_dim],minval=<span class="number">0</span>,maxval=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li><li><p>tf.randon_normal()生成正太分布的随机数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">random_tsr=tf.random_normal([row_dim,col_dim],mean=<span class="number">0.0</span>,stddev=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure></li><li><p>tf.truncated_normal()生成带有指定边界的正太分布的随机数，其正态分布的随机数位于指定均值（期望）到两个标准差之间的区间：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">runcnorm_tsr=tf.truncated_normal([row_dim,col_dim],mean=<span class="number">0.0</span>,stddev=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure></li><li><p>tf.random_shuffle()和tf.random_crop()可以实现张量/数组的随机化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shuffled_output=tf.random_shuffle(input_tenspr)</span><br><span class="line">cropped_output=tf.random_crop(input_tensor,crop_size)</span><br></pre></td></tr></table></figure></li><li><p>tf.random_crop()可以实现对张量指定大小的随机剪裁，为了固定剪裁结果的一个维度，需要在相应的维度上赋其最大值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cropped_image=tf.random_crop(my_image,[height/<span class="number">2</span>,width/<span class="number">2</span>,<span class="number">3</span>])</span><br></pre></td></tr></table></figure></li></ul></li></ul><ol start="2"><li>把张量封装为变量:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mt_var=tf.Variable(tf.zeros([row_dim,col_dim]))</span><br></pre></td></tr></table></figure></li></ol><h1 id="使用占位符和变量"><a href="#使用占位符和变量" class="headerlink" title="使用占位符和变量"></a>使用占位符和变量</h1><p>变量是TensorFlow机器学习算法的参数，TensorFlow维护（调整）这些变量的状态来优化机器学习算法。占位符是TensorFlow对象，用于表示输入输出数据的格式，允许传入指定类型和形状的数据，并依赖计算图的计算结果。</p><ol><li><p>使用tf.Variable()函数创建变量，输入一个张量，返回一个变量。声明变量之后需要初始化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">my_var=tf.Variable(tf.zeros([<span class="number">2</span>,<span class="number">3</span>]))</span><br><span class="line">sess=tf.Session()</span><br><span class="line">initialize_op=tf.global_variable_initializer()</span><br><span class="line">sess.run(initialize_op)</span><br></pre></td></tr></table></figure></li><li><p>占位符仅仅声明数据位置，用于传入数据到计算图。占位符通过会话的feed_dict参数获取数据。在计算图中使用占位符时，必须在其上执行至少一个操作。在TensorFlow中，初始化计算图，声明一个占位符x，定义y为x的identity操作。identity操作返回占位符传入的数据本身。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sess=tf.Session()</span><br><span class="line">x=tf.placeholder(tf.float32,shape=[<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">y=tf.identity(x)</span><br><span class="line">x_vals=np.random.rand(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">sess.run(y,feed_dict=&#123;x:x_vals&#125;)</span><br><span class="line"><span class="comment"># Note that sess.run(x,feed_dict=&#123;x:x_vals&#125;) will result in a self-referencing error.</span></span><br></pre></td></tr></table></figure></li></ol><h1 id="操作矩阵"><a href="#操作矩阵" class="headerlink" title="操作矩阵"></a>操作矩阵</h1><ul><li>创建一个图会话：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">sess=tf.Session()</span><br></pre></td></tr></table></figure></li></ul><ul><li>创建矩阵：<ul><li>使用numpy创建二维矩阵</li><li>使用创建张量的函数（zeros(),ones(),truncated_normal()等），并为其指定一个二维形状 </li><li>使用diag()函数从一个一维矩阵来创建对角矩阵<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">identity_matrix=tf.diag([<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">1.0</span>])</span><br><span class="line">A=tf.truncated_normal([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">B=tf.fill([<span class="number">2</span>,<span class="number">3</span>],<span class="number">5.0</span>)</span><br><span class="line">C=tf.random_uniform([<span class="number">3</span>,<span class="number">2</span>])</span><br><span class="line">D=tf.convert_to_tensor(np.array([[<span class="number">1.</span>,<span class="number">2.</span>,<span class="number">3.</span>],[<span class="number">-3.</span>,<span class="number">-7.</span>,<span class="number">-1.</span>],[<span class="number">0.</span>,<span class="number">5.</span>,<span class="number">-2.</span>,]]))</span><br><span class="line">print(sess.run(identity_matrix))</span><br><span class="line">[[<span class="number">1.</span>  <span class="number">0.</span>  <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span>  <span class="number">1.</span>  <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span>  <span class="number">0.</span>  <span class="number">1.</span>]]</span><br><span class="line">print(sess.run(A))</span><br><span class="line">[[ <span class="number">0.96751703</span>   <span class="number">0.11397751</span>  <span class="number">-0.3438891</span>]</span><br><span class="line"> [<span class="number">-0.10132604</span>  <span class="number">-0.8432678</span>   <span class="number">0.29810596</span>]]</span><br><span class="line">print(sess.run(B))</span><br><span class="line">[[<span class="number">5.</span>  <span class="number">5.</span>  <span class="number">5.</span> ]</span><br><span class="line"> [<span class="number">5.</span>  <span class="number">5.</span>  <span class="number">5.</span>]]</span><br><span class="line">print(sess.run(C))</span><br><span class="line">[[<span class="number">0.33184157</span>  <span class="number">0.08907614</span>]</span><br><span class="line"> [<span class="number">0.53189191</span>  <span class="number">0.67605299</span>]</span><br><span class="line"> [<span class="number">0.95889051</span>  <span class="number">0.67061249</span>]]</span><br><span class="line">print(sess.run(D))</span><br><span class="line">[[ <span class="number">1.</span>   <span class="number">2.</span>  <span class="number">3.</span>]</span><br><span class="line"> [<span class="number">-3.</span>  <span class="number">-7.</span> <span class="number">-1.</span>]</span><br><span class="line"> [ <span class="number">0.</span>   <span class="number">5.</span> <span class="number">-2.</span>]]</span><br></pre></td></tr></table></figure></li></ul></li></ul><ul><li>矩阵的加减法：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(A+B))</span><br><span class="line">[[<span class="number">4.61596632</span>  <span class="number">5.39771316</span>   <span class="number">4.4325695</span>]</span><br><span class="line"> [<span class="number">3.26702736</span>  <span class="number">5.14477345</span>  <span class="number">4.98265553</span>]]</span><br><span class="line">print(sess.run(B-B))</span><br><span class="line">[[<span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span>  <span class="number">0.</span>  <span class="number">0.</span>]]</span><br></pre></td></tr></table></figure></li></ul><ul><li>矩阵的乘法：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.matmul(B,identity_matrix)))</span><br><span class="line">[[<span class="number">5.</span>  <span class="number">5.</span>  <span class="number">5.</span>]</span><br><span class="line"> [<span class="number">5.</span>  <span class="number">5.</span>  <span class="number">5.</span>]]</span><br></pre></td></tr></table></figure></li></ul><ul><li>矩阵转置：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.transpose(C)))</span><br><span class="line">[[<span class="number">0.67124544</span>  <span class="number">0.26766731</span>  <span class="number">0.99068872</span>]</span><br><span class="line"> [<span class="number">0.25006068</span>  <span class="number">0.86560275</span>  <span class="number">0.58411312</span>]]</span><br></pre></td></tr></table></figure></li></ul><ul><li>矩阵行列式的使用：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.matrix_determinant(D)))</span><br><span class="line"><span class="number">-38.0</span></span><br></pre></td></tr></table></figure></li></ul><ul><li>逆矩阵：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.matrix_inverse(D)))</span><br><span class="line">[[<span class="number">-0.5</span>        <span class="number">-0.5</span>        <span class="number">-0.5</span>      ]</span><br><span class="line"> [<span class="number">0.15789474</span>  <span class="number">0.05263158</span>  <span class="number">0.21052632</span>]</span><br><span class="line"> [<span class="number">0.39473684</span>  <span class="number">0.13157895</span>  <span class="number">0.02631579</span>]]</span><br></pre></td></tr></table></figure></li></ul><ul><li>矩阵的分解：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.cholesky(identity_matrix)))</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>]]</span><br></pre></td></tr></table></figure></li></ul><ul><li>矩阵的特征值和特征向量：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.self_adjoint_eig(D)))     <span class="comment">#第一行为特征值，剩余的向量是对应的特征向量</span></span><br><span class="line">[[<span class="number">-10.65907521</span> <span class="number">-0.22750691</span>  <span class="number">2.88658212</span>]</span><br><span class="line"> [  <span class="number">0.21749542</span>  <span class="number">0.63250104</span> <span class="number">-0.74339638</span>]</span><br><span class="line"> [  <span class="number">0.84526515</span>  <span class="number">0.2587998</span>   <span class="number">0.46749277</span>]</span><br><span class="line"> [  <span class="number">-0.4880805</span>  <span class="number">0.73004459</span>  <span class="number">0.47834331</span>]]</span><br></pre></td></tr></table></figure></li></ul><h1 id="张量的基本操作"><a href="#张量的基本操作" class="headerlink" title="张量的基本操作"></a>张量的基本操作</h1><p>TensorFlow张量的基本操作有：add()、sub()、mul()、div()、mod()</p><ul><li>值得注意的是，div()函数返回值的数据类型与输入类型一致。所以，在Python2中，整数除法的实际返回是商的向下取整；而在Python3中，TensorFlow提供truediv()函数，其会在除法操作前强制转换整数为浮点数，所以最终的除法结果是浮点数。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.div(<span class="number">3</span>,<span class="number">4</span>)))</span><br><span class="line"><span class="number">0</span></span><br><span class="line">print(sess.run(tf.truediv(<span class="number">3</span>,<span class="number">4</span>)))</span><br><span class="line"><span class="number">0.75</span></span><br></pre></td></tr></table></figure></li></ul><ul><li>如果要对浮点数进行整数除法，可以使用floordiv()函数。此函数也返回浮点数结果，但是其会向下舍去小数位到最近的整数。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.floordiv(<span class="number">3.0</span>,<span class="number">4.0</span>)))</span><br><span class="line"><span class="number">0.0</span></span><br></pre></td></tr></table></figure></li></ul><ul><li>cross()函数用来计算两个张量间的点积。点积只为三维向量而定义，所以cross()函数的输入是两个三维向量：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.cross([<span class="number">1.</span>,<span class="number">0.</span>,<span class="number">0.</span>],[<span class="number">0.</span>,<span class="number">1.</span>,<span class="number">0.</span>])))</span><br><span class="line">[<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.0</span>]</span><br></pre></td></tr></table></figure></li></ul><ul><li>其他数学函数：<br>abs()<br>ceil()<br>cos()<br>exp()<br>floor()<br>inv()：返回输入参数张量的倒数<br>log()<br>maximum()<br>minimum()<br>neg()：返回输入参数张量的负值<br>pow()：返回输入参数第一个张量的第二个张量的次幂<br>round()：返回输入参数张量的四舍五入结果<br>rsqrt()：返回输入参数张量的平方根的倒数<br>sign()：根据输入参数张量的符号，返回-1、0或1<br>sin()<br>sqrt()：返回输入参数张量的平方根<br>square()<br>digamma()：普西（Psi）函数，lgamma()函数的导数<br>erf()：返回张量的高斯误差函数<br>erfc()：返回张量的互补误差函数<br>igamma()：返回下不完全伽马函数<br>igammac()：返回上不完全伽马函数<br>lbeta()：返回贝塔函数绝对值的自然对数<br>lgamma()：返回伽马函数绝对值的自然对数<br>squared_difference()：返回两个张量间差值的平方</li></ul><h1 id="实现激励函数"><a href="#实现激励函数" class="headerlink" title="实现激励函数"></a>实现激励函数</h1><p>TensorFlow的激励函数位于神经网络（neural network，nn）库。</p><ol><li><p>整流线性单元（Rectifier Linear Unit，ReLU）<br>神经网络最常用的非线性函数。其函数为max(0,x)，连续但不平滑。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.nn.relu([<span class="number">-3.</span>,<span class="number">3.</span>,<span class="number">10.</span>])))</span><br><span class="line">[<span class="number">0.</span>  <span class="number">3.</span>  <span class="number">10.</span>]</span><br></pre></td></tr></table></figure></li><li><p>ReLU6<br>有时为了抵消ReLU激励函数的线性增长部分，会在min()函数中嵌入max(0,x)，其在TensorFlow中的实现称为ReLU6，表示为min(max(0,x),6)。这是hard-sigmoid函数的变种，计算运行速度快，解决了梯度消失（无限趋近于0）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.nn.relu6([<span class="number">-3.</span>,<span class="number">3.</span>,<span class="number">10.</span>])))</span><br><span class="line">[<span class="number">0.</span>  <span class="number">3.</span>  <span class="number">6.</span>]</span><br></pre></td></tr></table></figure></li><li><p>sigmoid函数<br>最常用的连续，平滑的激励函数。它也被称作逻辑函数（Logistic函数），表示为1/(1+exp(-x))。sigmoid函数由于在机器学习训练过程中反向传播项趋近于0.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.nn.sigmoid([<span class="number">-1.</span>,<span class="number">0.</span>,<span class="number">1.</span>])))</span><br><span class="line">[<span class="number">0.26894143</span>  <span class="number">0.5</span>  <span class="number">0.7310586</span>]</span><br></pre></td></tr></table></figure></li><li><p>双曲正切函数（hyper tangent,tanh）<br>双曲正弦与双曲余弦的比值，另一种写法是(exp(x)-exp(-x))/(exp(x)+exp(-x))</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.nn.tanh([<span class="number">-1.</span>,<span class="number">0.</span>,<span class="number">1.</span>])))</span><br><span class="line">[<span class="number">-0.76159418</span>  <span class="number">0.</span>  <span class="number">0.76159418</span>]</span><br></pre></td></tr></table></figure></li><li><p>softsign函数<br>符号函数的连续估计，表达式：x/(abs(x)+1)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.nn.softsign([<span class="number">-1.</span>,<span class="number">0.</span>,<span class="number">-1.</span>])))</span><br><span class="line">[<span class="number">-0.5</span> <span class="number">0.</span> <span class="number">0.5</span>]</span><br></pre></td></tr></table></figure></li><li><p>softplus激励函数<br>ReLU激励函数的平滑版，表达式为log(exp(x)+1)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.nn.softplus([<span class="number">-1.</span>,<span class="number">0.</span>,<span class="number">-1.</span>])))</span><br><span class="line">[<span class="number">0.31326166</span> <span class="number">0.69314718</span> <span class="number">1.31326163</span>]</span><br></pre></td></tr></table></figure></li><li><p>ELU激励函数（Exponential Linear Unit,ELU）<br>与softplus激励函数相似，区别在于：当输入无限小时，ELU激励函数趋近于-1，而softplus激励函数趋近于0。表达式为(exp(x)+1) if x&lt;0 else x</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(tf.nn.elu([<span class="number">-1.</span>,<span class="number">0.</span>,<span class="number">-1.</span>])))</span><br><span class="line">[<span class="number">-0.63212055</span> <span class="number">0.</span> <span class="number">1.</span>]</span><br></pre></td></tr></table></figure></li></ol><h1 id="读取数据源"><a href="#读取数据源" class="headerlink" title="读取数据源"></a>读取数据源</h1><ol><li><p>鸢尾花卉数据集（Iris data）<br>此样本数据是机器学习和统计分析最经典的数据集，包含鸢尾花、变色鸢尾和维吉尼亚鸢尾各自的花萼和花瓣的长度和宽度。总共有150个数据集，每类有50个样本。用Python加载样本数据集时，可以使用Scikit Learn的数据集函数，使用方式如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">print(len(iris.data))</span><br><span class="line"><span class="number">150</span></span><br><span class="line">print(len(iris.target))</span><br><span class="line"><span class="number">150</span></span><br><span class="line">print(iris.data[<span class="number">0</span>])         <span class="comment">#Sepal length, Sepal width, Petal length, Petal width</span></span><br><span class="line">[<span class="number">5.1</span> <span class="number">3.5</span> <span class="number">1.4</span> <span class="number">0.2</span>]</span><br><span class="line">print(set(iris.target))     <span class="comment"># Ⅰ. setosa, Ⅱ. virginica, Ⅲ. versicolor</span></span><br><span class="line">&#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>&#125;</span><br></pre></td></tr></table></figure></li><li><p>出生体重数据（Birth weight data）<br>此样本数据集是婴儿出生体重以及母亲和家庭历史人口统计学、医学指标，有189个样本集，包含11个特征变量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">birthdata_url = <span class="string">'https://www.umass.edu/statdata/statdata/data/lowbwt.dat'</span></span><br><span class="line">birth_file = requests.get(birthdata_url)</span><br><span class="line">birth_data = birth_file.text.split(<span class="string">'\r\n'</span>)[<span class="number">5</span>:]</span><br><span class="line">birth_header = [x <span class="keyword">for</span> x <span class="keyword">in</span> birth_data[<span class="number">0</span>].split(<span class="string">' '</span>) <span class="keyword">if</span> len(x)&gt;=<span class="number">1</span>]</span><br><span class="line">birth_data = [[float(x) <span class="keyword">for</span> x <span class="keyword">in</span> y.split(<span class="string">' '</span>) <span class="keyword">if</span> len(x)&gt;=<span class="number">1</span>] <span class="keyword">for</span> y <span class="keyword">in</span> birth_data[<span class="number">1</span>:] <span class="keyword">if</span> len(y)&gt;=<span class="number">1</span>]</span><br><span class="line">print(len(birth_data))            <span class="comment">#189</span></span><br><span class="line">print(len(birth_data[<span class="number">0</span>]))         <span class="comment">#11</span></span><br></pre></td></tr></table></figure></li><li><p>波士顿房价数据（Boston Housing data）<br>此样本数据集保存在卡内基梅隆大学机器学习仓库，总共有506个房价样本，包含14个特征变量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">housing_url = <span class="string">'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'</span></span><br><span class="line">housing_header = [<span class="string">'CRIM'</span>, <span class="string">'ZN'</span>, <span class="string">'INDUS'</span>, <span class="string">'CHAS'</span>, <span class="string">'NOX'</span>, <span class="string">'RM'</span>, <span class="string">'AGE'</span>, <span class="string">'DIS'</span>, <span class="string">'RAD'</span>, <span class="string">'TAX'</span>, <span class="string">'PTRATIO'</span>, <span class="string">'B'</span>, <span class="string">'LSTAT'</span>, <span class="string">'MEDV'</span>]</span><br><span class="line">housing_file = requests.get(housing_url)</span><br><span class="line">housing_data = [[float(x) <span class="keyword">for</span> x <span class="keyword">in</span> y.split(<span class="string">' '</span>) <span class="keyword">if</span> len(x)&gt;=<span class="number">1</span>] <span class="keyword">for</span> y <span class="keyword">in</span> housing_file.text.split(<span class="string">'\n'</span>) <span class="keyword">if</span> len(y)&gt;=<span class="number">1</span>]</span><br><span class="line">print(len(housing_data))         <span class="comment">#506</span></span><br><span class="line">print(len(housing_data[<span class="number">0</span>]))      <span class="comment">#14</span></span><br></pre></td></tr></table></figure></li><li><p>MNIST手写体字库<br>MNIST手写体字库是NIST手写体字库的子样本数据集，网址：<a href="https://yann.lecun.com/exdb/mnist" target="_blank" rel="noopener">https://yann.lecun.com/exdb/mnist</a> 包含70000张0到9的图像，其中60000张标注为训练样本数据集，10000张为测试样本数据集。TensorFlow提供内建函数访问。MNIST常用来进行图像识别训练。为了预防过拟合，需要提供验证数据集。TensorFlow从训练样本数据集中留出5000张图片作为验证样本数据集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data/"</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line">print(len(mnist.train.images))          <span class="comment">#55000</span></span><br><span class="line">print(len(mnist.test.images))           <span class="comment">#10000</span></span><br><span class="line">print(len(mnist.validation.images))     <span class="comment">#5000</span></span><br><span class="line">print(mnist.train.labels[<span class="number">1</span>,:])          <span class="comment">#[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]</span></span><br></pre></td></tr></table></figure></li><li><p>垃圾短信文本数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">from</span> zipfile <span class="keyword">import</span> ZipFile</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get/read zip file</span></span><br><span class="line">zip_url = <span class="string">'http://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'</span></span><br><span class="line">r = requests.get(zip_url)</span><br><span class="line">z = ZipFile(io.BytesIO(r.content))</span><br><span class="line">file = z.read(<span class="string">'SMSSpamCollection'</span>)</span><br><span class="line"><span class="comment"># Format Data</span></span><br><span class="line">text_data = file.decode()</span><br><span class="line">text_data = text_data.encode(<span class="string">'ascii'</span>,errors=<span class="string">'ignore'</span>)</span><br><span class="line">text_data = text_data.decode().split(<span class="string">'\n'</span>)</span><br><span class="line">text_data = [x.split(<span class="string">'\t'</span>) <span class="keyword">for</span> x <span class="keyword">in</span> text_data <span class="keyword">if</span> len(x)&gt;=<span class="number">1</span>]</span><br><span class="line">[text_data_target, text_data_train] = [list(x) <span class="keyword">for</span> x <span class="keyword">in</span> zip(*text_data)]</span><br><span class="line">print(len(text_data_train))           <span class="comment">#5574</span></span><br><span class="line">print(set(text_data_target))          <span class="comment">#&#123;'ham','spam'&#125;</span></span><br><span class="line">print(text_data_train[<span class="number">1</span>])             <span class="comment">#OK lar...Joking wif u oni</span></span><br></pre></td></tr></table></figure></li><li><p>影评样本数据集<br>此样本数据集是观影者的影评，分为好评和差评。位于康奈尔大学的仓库：<a href="http://www.cs.cornell.edu/people/pabo/movie-review-data" target="_blank" rel="noopener">http://www.cs.cornell.edu/people/pabo/movie-review-data</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tarfile</span><br><span class="line"></span><br><span class="line">movie_data_url = <span class="string">'http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz'</span></span><br><span class="line">r = requests.get(movie_data_url)</span><br><span class="line"><span class="comment"># Stream data into temp object</span></span><br><span class="line">stream_data = io.BytesIO(r.content)</span><br><span class="line">tmp = io.BytesIO()</span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    s = stream_data.read(<span class="number">16384</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> s:  </span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    tmp.write(s)</span><br><span class="line">stream_data.close()</span><br><span class="line">tmp.seek(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># Extract tar file</span></span><br><span class="line">tar_file = tarfile.open(fileobj=tmp, mode=<span class="string">"r:gz"</span>)</span><br><span class="line">pos = tar_file.extractfile(<span class="string">'rt-polaritydata/rt-polarity.pos'</span>)</span><br><span class="line">neg = tar_file.extractfile(<span class="string">'rt-polaritydata/rt-polarity.neg'</span>)</span><br><span class="line"><span class="comment"># Save pos/neg reviews</span></span><br><span class="line">pos_data = []</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> pos:</span><br><span class="line">    pos_data.append(line.decode(<span class="string">'ISO-8859-1'</span>).encode(<span class="string">'ascii'</span>,errors=<span class="string">'ignore'</span>).decode())</span><br><span class="line">neg_data = []</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> neg:</span><br><span class="line">    neg_data.append(line.decode(<span class="string">'ISO-8859-1'</span>).encode(<span class="string">'ascii'</span>,errors=<span class="string">'ignore'</span>).decode())</span><br><span class="line">tar_file.close()</span><br><span class="line"></span><br><span class="line">print(len(pos_data))              <span class="comment">#5531</span></span><br><span class="line">print(len(neg_data))              <span class="comment">#5331</span></span><br><span class="line">print(neg_data[<span class="number">0</span>])                <span class="comment">#simplistic,silly and tedious</span></span><br></pre></td></tr></table></figure></li><li><p>莎士比亚著作文本数据集（Shakespeare text data）<br>此样本数据集是古登堡数字电子书计划提供的免费电子书籍，他们编译了莎士比亚所有著作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">shakespeare_url = <span class="string">'http://www.gutenberg.org/cache/epub/100/pg100.txt'</span></span><br><span class="line"><span class="comment"># Get Shakespeare text</span></span><br><span class="line">response = requests.get(shakespeare_url)</span><br><span class="line">shakespeare_file = response.content</span><br><span class="line"><span class="comment"># Decode binary into string</span></span><br><span class="line">shakespeare_text = shakespeare_file.decode(<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="comment"># Drop first few descriptive paragraphs.</span></span><br><span class="line">shakespeare_text = shakespeare_text[<span class="number">7675</span>:]</span><br><span class="line">print(len(shakespeare_text))            <span class="comment">#Number of characters：5582212</span></span><br></pre></td></tr></table></figure></li><li><p>英德句子翻译样本集<br>此数据集由在线翻译数据库Tatoeba发布，ManyThings.org整理并提供下载。这里提供英德语句互译的文本文件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">from</span> zipfile <span class="keyword">import</span> ZipFile</span><br><span class="line">sentence_url = <span class="string">'http://www.manythings.org/anki/deu-eng.zip'</span></span><br><span class="line">r = requests.get(sentence_url)</span><br><span class="line">z = ZipFile(io.BytesIO(r.content))</span><br><span class="line">file = z.read(<span class="string">'deu.txt'</span>)</span><br><span class="line"><span class="comment"># Format Data</span></span><br><span class="line">eng_ger_data = file.decode()</span><br><span class="line">eng_ger_data = eng_ger_data.encode(<span class="string">'ascii'</span>,errors=<span class="string">'ignore'</span>)</span><br><span class="line">eng_ger_data = eng_ger_data.decode().split(<span class="string">'\n'</span>)</span><br><span class="line">eng_ger_data = [x.split(<span class="string">'\t'</span>) <span class="keyword">for</span> x <span class="keyword">in</span> eng_ger_data <span class="keyword">if</span> len(x)&gt;=<span class="number">1</span>]</span><br><span class="line">[english_sentence, german_sentence] = [list(x) <span class="keyword">for</span> x <span class="keyword">in</span> zip(*eng_ger_data)]</span><br><span class="line">print(len(english_sentence))         <span class="comment">#137673</span></span><br><span class="line">print(len(german_sentence))          <span class="comment">#137673</span></span><br><span class="line">print(eng_ger_data[<span class="number">10</span>])              <span class="comment">#['I won!,' 'Ich habe gewonnen！']</span></span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TensorFlow算法的一般流程&quot;&gt;&lt;a href=&quot;#TensorFlow算法的一般流程&quot; class=&quot;headerlink&quot; title=&quot;TensorFlow算法的一般流程&quot;&gt;&lt;/a&gt;TensorFlow算法的一般流程&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;导入/生
      
    
    </summary>
    
      <category term="学习笔记" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>TFMLC学习笔记（0）序言</title>
    <link href="http://yoursite.com/2018/04/20/TFMLC-0/"/>
    <id>http://yoursite.com/2018/04/20/TFMLC-0/</id>
    <published>2018-04-19T17:56:41.000Z</published>
    <updated>2018-04-19T18:39:56.538Z</updated>
    
    <content type="html"><![CDATA[<h1 id="书籍信息"><a href="#书籍信息" class="headerlink" title="书籍信息"></a>书籍信息</h1><ul><li>书名：TensorFlow机器学习实战指南</li></ul><ul><li>作者：[美]尼克·麦克卢尔</li></ul><ul><li>译者：曾益强</li></ul><ul><li>出版社：机械工业出版社</li></ul><h1 id="Book-Information"><a href="#Book-Information" class="headerlink" title="Book Information"></a>Book Information</h1><ul><li>Name: TensorFlow Machine Learning Cookbook</li></ul><ul><li>Author: Nike McClure</li></ul><ul><li>Publisher: Packt Publishing</li></ul><h1 id="环境搭建-软件清单"><a href="#环境搭建-软件清单" class="headerlink" title="环境搭建+软件清单"></a>环境搭建+软件清单</h1><ul><li>Python3</li></ul><ul><li>TensorFlow</li></ul><ul><li>numpy</li></ul><ul><li>scipy</li></ul><ul><li>sklearn</li></ul><ul><li>jupyter</li></ul><ul><li>matplotlib</li></ul><ul><li>requests</li></ul><ul><li>Pillow</li></ul><h1 id="源码下载"><a href="#源码下载" class="headerlink" title="源码下载"></a>源码下载</h1><ul><li><a href="https://github.com/nfmcclure/tensorflow_cookbook" target="_blank" rel="noopener">GitHub</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;书籍信息&quot;&gt;&lt;a href=&quot;#书籍信息&quot; class=&quot;headerlink&quot; title=&quot;书籍信息&quot;&gt;&lt;/a&gt;书籍信息&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;书名：TensorFlow机器学习实战指南&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;作者：[美]尼克·麦克卢尔&lt;
      
    
    </summary>
    
      <category term="学习笔记" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2018/04/19/hello-world/"/>
    <id>http://yoursite.com/2018/04/19/hello-world/</id>
    <published>2018-04-18T17:38:21.578Z</published>
    <updated>2018-04-18T17:38:21.579Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
